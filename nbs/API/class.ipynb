{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed122c74",
   "metadata": {},
   "source": [
    "# Class\n",
    "\n",
    "- order: 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb97d9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp _class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5d586f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from __future__ import annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd32470",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "import nbdev\n",
    "nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb6e991",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "__version__ = \"0.3.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a49e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def cohens_d(control, test, is_paired=False):\n",
    "    \"\"\"\n",
    "    Computes Cohen's d for test v.s. control.\n",
    "    See https://en.wikipedia.org/wiki/Effect_size#Cohen's_d\n",
    "\n",
    "    Keywords\n",
    "    --------\n",
    "    control, test: List, tuple, or array.\n",
    "\n",
    "    is_paired: boolean, default False\n",
    "        If True, the paired Cohen's d is returned.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        d: float.\n",
    "            If is_paired is False, this is equivalent to:\n",
    "            (numpy.mean(test) - numpy.mean(control))  / pooled StDev\n",
    "\n",
    "            If is_paired is True, returns\n",
    "            (numpy.mean(test) - numpy.mean(control))  / average StDev\n",
    "\n",
    "            The pooled standard deviation is equal to:\n",
    "\n",
    "                   (n1 - 1) * var(control) + (n2 - 1) * var (test)\n",
    "            sqrt(  ---------------------------------------------- )\n",
    "                           (n1 + n2 - 2)\n",
    "\n",
    "\n",
    "            The average standard deviation is equal to:\n",
    "\n",
    "\n",
    "                  var(control) + var(test)\n",
    "            sqrt( ------------------------- )\n",
    "                             2\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    The sample variance (and standard deviation) uses N-1 degrees of freedoms.\n",
    "    This is an application of Bessel's correction, and yields the unbiased\n",
    "    sample variance.\n",
    "\n",
    "    References:\n",
    "        https://en.wikipedia.org/wiki/Bessel%27s_correction\n",
    "        https://en.wikipedia.org/wiki/Standard_deviation#Corrected_sample_standard_deviation\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "\n",
    "    # Convert to numpy arrays for speed.\n",
    "    # NaNs are automatically dropped.\n",
    "    if control.__class__ != np.ndarray:\n",
    "        control = np.array(control)\n",
    "    if test.__class__ != np.ndarray:\n",
    "        test    = np.array(test)\n",
    "    control = control[~np.isnan(control)]\n",
    "    test    = test[~np.isnan(test)]\n",
    "\n",
    "    pooled_sd, average_sd = _compute_standardizers(control, test)\n",
    "    # pooled SD is used for Cohen's d of two independant groups.\n",
    "    # average SD is used for Cohen's d of two paired groups\n",
    "    # (aka repeated measures).\n",
    "    # NOT IMPLEMENTED YET: Correlation adjusted SD is used for Cohen's d of\n",
    "    # two paired groups but accounting for the correlation between\n",
    "    # the two groups.\n",
    "\n",
    "    if is_paired:\n",
    "        # Check control and test are same length.\n",
    "        if len(control) != len(test):\n",
    "            raise ValueError(\"`control` and `test` are not the same length.\")\n",
    "        # assume the two arrays are ordered already.\n",
    "        delta = test - control\n",
    "        M = np.mean(delta)\n",
    "        divisor = average_sd\n",
    "\n",
    "    else:\n",
    "        M = np.mean(test) - np.mean(control)\n",
    "        divisor = pooled_sd\n",
    "        \n",
    "    return M / divisor\n",
    "\n",
    "def weighted_delta(difference, group_var):\n",
    "    import numpy as np\n",
    "\n",
    "    weight = np.true_divide(1, group_var)\n",
    "    return np.sum(difference*weight)/np.sum(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d18132d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def create_jackknife_indexes(data):\n",
    "    \"\"\"\n",
    "    Given an array-like, creates a jackknife bootstrap.\n",
    "\n",
    "    For a given set of data Y, the jackknife bootstrap sample J[i]\n",
    "    is defined as the data set Y with the ith data point deleted.\n",
    "\n",
    "    Keywords\n",
    "    --------\n",
    "    data: array-like\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Generator that yields all jackknife bootstrap samples.\n",
    "    \"\"\"\n",
    "    from numpy import arange, delete\n",
    "\n",
    "    index_range = arange(0, len(data))\n",
    "    return (delete(index_range, i) for i in index_range)\n",
    "\n",
    "\n",
    "def compute_1group_jackknife(x, func, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    Returns the jackknife bootstraps for func(x).\n",
    "    \"\"\"\n",
    "    jackknives = [i for i in create_jackknife_indexes(x)]\n",
    "    out = [func(x[j], *args, **kwargs) for j in jackknives]\n",
    "    del jackknives # memory management.\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1c4b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def _compute_alpha_from_ci(ci):\n",
    "    if ci < 0 or ci > 100:\n",
    "        raise ValueError(\"`ci` must be a number between 0 and 100.\")\n",
    "\n",
    "    return (100. - ci) / 100.\n",
    "\n",
    "def calculate_group_var(control_var, control_N,test_var, test_N):\n",
    "    return control_var/control_N + test_var/test_N\n",
    "\n",
    "def calculate_weighted_delta(group_var, differences, resamples):\n",
    "    '''\n",
    "    Compute the weighted deltas.\n",
    "    '''\n",
    "    import numpy as np\n",
    "\n",
    "    weight = 1/group_var\n",
    "    denom = np.sum(weight)\n",
    "    num = np.sum(weight[i] * differences[i] for i in range(0, len(weight)))\n",
    "\n",
    "    return num/denom\n",
    "\n",
    "def compute_meandiff_bias_correction(bootstraps, effsize):\n",
    "    \"\"\"\n",
    "    Computes the bias correction required for the BCa method\n",
    "    of confidence interval construction.\n",
    "\n",
    "    Keywords\n",
    "    --------\n",
    "    bootstraps: array-like\n",
    "        An numerical iterable, comprising bootstrap resamples\n",
    "        of the effect size.\n",
    "\n",
    "    effsize: numeric\n",
    "        The effect size for the original sample.\n",
    "\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bias: numeric\n",
    "        The bias correction value for the given bootstraps\n",
    "        and effect size.\n",
    "\n",
    "    \"\"\"\n",
    "    from scipy.stats import norm\n",
    "    from numpy import array\n",
    "\n",
    "    B = array(bootstraps)\n",
    "    prop_less_than_es = sum(B < effsize) / len(B)\n",
    "\n",
    "    return norm.ppf(prop_less_than_es)\n",
    "\n",
    "def _calc_accel(jack_dist):\n",
    "    from numpy import mean as npmean\n",
    "    from numpy import sum as npsum\n",
    "    from numpy import errstate\n",
    "\n",
    "    jack_mean = npmean(jack_dist)\n",
    "\n",
    "    numer = npsum((jack_mean - jack_dist)**3)\n",
    "    denom = 6.0 * (npsum((jack_mean - jack_dist)**2) ** 1.5)\n",
    "\n",
    "    with errstate(invalid='ignore'):\n",
    "        # does not raise warning if invalid division encountered.\n",
    "        return numer / denom\n",
    "    \n",
    "def compute_interval_limits(bias, acceleration, n_boots, ci=95):\n",
    "    \"\"\"\n",
    "    Returns the indexes of the interval limits for a given bootstrap.\n",
    "\n",
    "    Supply the bias, acceleration factor, and number of bootstraps.\n",
    "    \"\"\"\n",
    "    from scipy.stats import norm\n",
    "    from numpy import isnan, nan\n",
    "\n",
    "    alpha = _compute_alpha_from_ci(ci)\n",
    "\n",
    "    alpha_low = alpha / 2\n",
    "    alpha_high = 1 - (alpha / 2)\n",
    "\n",
    "    z_low = norm.ppf(alpha_low)\n",
    "    z_high = norm.ppf(alpha_high)\n",
    "\n",
    "    kws = {'bias': bias, 'acceleration': acceleration}\n",
    "    low = _compute_quantile(z_low, **kws)\n",
    "    high = _compute_quantile(z_high, **kws)\n",
    "\n",
    "    if isnan(low) or isnan(high):\n",
    "        return low, high\n",
    "\n",
    "    else:\n",
    "        low = int(norm.cdf(low) * n_boots)\n",
    "        high = int(norm.cdf(high) * n_boots)\n",
    "        return low, high\n",
    "\n",
    "def _compute_alpha_from_ci(ci):\n",
    "    if ci < 0 or ci > 100:\n",
    "        raise ValueError(\"`ci` must be a number between 0 and 100.\")\n",
    "\n",
    "    return (100. - ci) / 100.\n",
    "\n",
    "def compute_meandiff_jackknife(x0, x1, is_paired, effect_size):\n",
    "    \"\"\"\n",
    "    Given two arrays, returns the jackknife for their effect size.\n",
    "    \"\"\"\n",
    "\n",
    "    jackknives = _create_two_group_jackknife_indexes(x0, x1, is_paired)\n",
    "\n",
    "    out = []\n",
    "\n",
    "    for j in jackknives:\n",
    "        x0_shuffled = x0[j[0]]\n",
    "        x1_shuffled = x1[j[1]]\n",
    "\n",
    "        es = two_group_difference(x0_shuffled, x1_shuffled,\n",
    "                                       is_paired, effect_size)\n",
    "        out.append(es)\n",
    "\n",
    "    return out\n",
    "\n",
    "def compute_bootstrapped_diff(x0, x1, is_paired, effect_size,\n",
    "                              resamples=5000, random_seed=12345):\n",
    "    \"\"\"Bootstraps the effect_size for 2 groups.\"\"\"\n",
    "    \n",
    "    import numpy as np\n",
    "    from numpy.random import PCG64, RandomState\n",
    "    \n",
    "    # rng = RandomState(default_rng(random_seed))\n",
    "    rng = RandomState(PCG64(random_seed))\n",
    "\n",
    "    out = np.repeat(np.nan, resamples)\n",
    "    x0_len = len(x0)\n",
    "    x1_len = len(x1)\n",
    "    \n",
    "    for i in range(int(resamples)):\n",
    "        \n",
    "        if is_paired:\n",
    "            if x0_len != x1_len:\n",
    "                raise ValueError(\"The two arrays do not have the same length.\")\n",
    "            random_idx = rng.choice(x0_len, x0_len, replace=True)\n",
    "            x0_sample = x0[random_idx]\n",
    "            x1_sample = x1[random_idx]\n",
    "        else:\n",
    "            x0_sample = rng.choice(x0, x0_len, replace=True)\n",
    "            x1_sample = rng.choice(x1, x1_len, replace=True)\n",
    "            \n",
    "        out[i] = two_group_difference(x0_sample, x1_sample,\n",
    "                                          is_paired, effect_size)\n",
    "    \n",
    "    # check whether there are any infinities in the bootstrap,\n",
    "    # which likely indicates the sample sizes are too small as\n",
    "    # the computation of Cohen's d and Hedges' g necessitated \n",
    "    # a division by zero.\n",
    "    # Added in v0.2.6.\n",
    "    \n",
    "    # num_infinities = len(out[np.isinf(out)])\n",
    "    # print(num_infinities)\n",
    "    # if num_infinities > 0:\n",
    "    #     warn_msg = \"There are {} bootstraps that are not defined. \"\\\n",
    "    #     \"This is likely due to smaple sample sizes. \"\\\n",
    "    #     \"The values in a bootstrap for a group will be more likely \"\\\n",
    "    #     \"to be all equal, with a resulting variance of zero. \"\\\n",
    "    #     \"The computation of Cohen's d and Hedges' g will therefore \"\\\n",
    "    #     \"involved a division by zero. \"\n",
    "    #     warnings.warn(warn_msg.format(num_infinities), category=\"UserWarning\")\n",
    "        \n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ffb19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class MiniMetaDelta(object):\n",
    "    \"\"\"\n",
    "    A class to compute and store the weighted mean differences.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, effectsizedataframe, permutation_count,\n",
    "                ci=95):\n",
    "\n",
    "        import numpy as np\n",
    "        from numpy import sort as npsort\n",
    "        from numpy import sqrt, isinf, isnan\n",
    "#         from ._stats_tools import effsize as es\n",
    "#         from ._stats_tools import confint_1group as ci1g\n",
    "#         from ._stats_tools import confint_2group_diff as ci2g\n",
    "\n",
    "        from string import Template\n",
    "        import warnings\n",
    "        \n",
    "        self.__effsizedf         = effectsizedataframe.results\n",
    "        self.__dabest_obj        = effectsizedataframe.dabest_obj\n",
    "        self.__ci                = ci\n",
    "        self.__resamples         = effectsizedataframe.resamples\n",
    "        self.__alpha             = _compute_alpha_from_ci(ci)\n",
    "        self.__permutation_count = permutation_count\n",
    "        self.__bootstraps        = np.array(self.__effsizedf[\"bootstraps\"])\n",
    "        self.__control           = np.array(self.__effsizedf[\"control\"])\n",
    "        self.__test              = np.array(self.__effsizedf[\"test\"])\n",
    "        self.__control_N         = np.array(self.__effsizedf[\"control_N\"])\n",
    "        self.__test_N            = np.array(self.__effsizedf[\"test_N\"])\n",
    "\n",
    "\n",
    "        idx  = self.__dabest_obj.idx\n",
    "        dat  = self.__dabest_obj._plot_data\n",
    "        xvar = self.__dabest_obj._xvar\n",
    "        yvar = self.__dabest_obj._yvar\n",
    "\n",
    "        control_var=[]\n",
    "        test_var=[]\n",
    "        for j, current_tuple in enumerate(idx):\n",
    "            cname = current_tuple[0]\n",
    "            control = dat[dat[xvar] == cname][yvar].copy()\n",
    "            control_var.append(np.var(control, ddof=1))\n",
    "\n",
    "            tname = current_tuple[1]\n",
    "            test = dat[dat[xvar] == tname][yvar].copy()\n",
    "            test_var.append(np.var(test, ddof=1))\n",
    "        \n",
    "        self.__control_var = np.array(control_var)\n",
    "        self.__test_var    = np.array(test_var)\n",
    "        self.__group_var   = calculate_group_var(self.__control_var, \n",
    "                                                 self.__control_N,\n",
    "                                                 self.__test_var, \n",
    "                                                 self.__test_N)\n",
    "\n",
    "        self.__bootstraps_weighted_delta = calculate_weighted_delta(\n",
    "                                                          self.__group_var, \n",
    "                                                          self.__bootstraps, \n",
    "                                                          self.__resamples)\n",
    "\n",
    "        self.__difference = weighted_delta(self.__effsizedf[\"difference\"],\n",
    "                                                   self.__group_var)\n",
    "\n",
    "        sorted_weighted_deltas = npsort(self.__bootstraps_weighted_delta)\n",
    "\n",
    "\n",
    "        self.__bias_correction = compute_meandiff_bias_correction(\n",
    "                                    self.__bootstraps_weighted_delta, self.__difference)\n",
    "        \n",
    "        self.__jackknives = np.array(compute_1group_jackknife(\n",
    "                                                self.__bootstraps_weighted_delta, \n",
    "                                                np.mean))\n",
    "\n",
    "        self.__acceleration_value = _calc_accel(self.__jackknives)\n",
    "\n",
    "        # Compute BCa intervals.\n",
    "        bca_idx_low, bca_idx_high = compute_interval_limits(\n",
    "            self.__bias_correction, self.__acceleration_value,\n",
    "            self.__resamples, ci)\n",
    "        \n",
    "        self.__bca_interval_idx = (bca_idx_low, bca_idx_high)\n",
    "\n",
    "        if ~isnan(bca_idx_low) and ~isnan(bca_idx_high):\n",
    "            self.__bca_low  = sorted_weighted_deltas[bca_idx_low]\n",
    "            self.__bca_high = sorted_weighted_deltas[bca_idx_high]\n",
    "\n",
    "            err1 = \"The $lim_type limit of the interval\"\n",
    "            err2 = \"was in the $loc 10 values.\"\n",
    "            err3 = \"The result should be considered unstable.\"\n",
    "            err_temp = Template(\" \".join([err1, err2, err3]))\n",
    "\n",
    "            if bca_idx_low <= 10:\n",
    "                warnings.warn(err_temp.substitute(lim_type=\"lower\",\n",
    "                                                  loc=\"bottom\"),\n",
    "                              stacklevel=1)\n",
    "\n",
    "            if bca_idx_high >= self.__resamples-9:\n",
    "                warnings.warn(err_temp.substitute(lim_type=\"upper\",\n",
    "                                                  loc=\"top\"),\n",
    "                              stacklevel=1)\n",
    "\n",
    "        else:\n",
    "            err1 = \"The $lim_type limit of the BCa interval cannot be computed.\"\n",
    "            err2 = \"It is set to the effect size itself.\"\n",
    "            err3 = \"All bootstrap values were likely all the same.\"\n",
    "            err_temp = Template(\" \".join([err1, err2, err3]))\n",
    "\n",
    "            if isnan(bca_idx_low):\n",
    "                self.__bca_low  = self.__difference\n",
    "                warnings.warn(err_temp.substitute(lim_type=\"lower\"),\n",
    "                              stacklevel=0)\n",
    "\n",
    "            if isnan(bca_idx_high):\n",
    "                self.__bca_high  = self.__difference\n",
    "                warnings.warn(err_temp.substitute(lim_type=\"upper\"),\n",
    "                              stacklevel=0)\n",
    "\n",
    "        # Compute percentile intervals.\n",
    "        pct_idx_low  = int((self.__alpha/2)     * self.__resamples)\n",
    "        pct_idx_high = int((1-(self.__alpha/2)) * self.__resamples)\n",
    "\n",
    "        self.__pct_interval_idx = (pct_idx_low, pct_idx_high)\n",
    "        self.__pct_low          = sorted_weighted_deltas[pct_idx_low]\n",
    "        self.__pct_high         = sorted_weighted_deltas[pct_idx_high]\n",
    "        \n",
    "    \n",
    "\n",
    "    def __permutation_test(self):\n",
    "        import numpy as np\n",
    "        self.__permutations     = np.array(self.__effsizedf[\"permutations\"])\n",
    "        self.__permutations_var = np.array(self.__effsizedf[\"permutations_var\"])\n",
    "\n",
    "        THRESHOLD = np.abs(self.__difference)\n",
    "\n",
    "        all_num = []\n",
    "        all_denom = []\n",
    "\n",
    "        groups = len(self.__permutations)\n",
    "        for i in range(0, len(self.__permutations[0])):\n",
    "            weight = [1/self.__permutations_var[j][i] for j in range(0, groups)]\n",
    "            all_num.append(np.sum([weight[j]*self.__permutations[j][i] for j in range(0, groups)]))\n",
    "            all_denom.append(np.sum(weight))\n",
    "        \n",
    "        output=[]\n",
    "        for i in range(0, len(all_num)):\n",
    "            output.append(all_num[i]/all_denom[i])\n",
    "        \n",
    "        self.__permutations_weighted_delta = np.array(output)\n",
    "\n",
    "        count = sum(np.abs(self.__permutations_weighted_delta)>THRESHOLD)\n",
    "        self.__pvalue_permutation = count/self.__permutation_count\n",
    "\n",
    "\n",
    "\n",
    "    def __repr__(self, header=True, sigfig=3):\n",
    "        # from .__init__ import __version__\n",
    "        import datetime as dt\n",
    "        import numpy as np\n",
    "\n",
    "        from .misc_tools import print_greeting\n",
    "        \n",
    "        is_paired = self.__dabest_obj.is_paired\n",
    "\n",
    "        PAIRED_STATUS = {'baseline'   : 'paired', \n",
    "                         'sequential' : 'paired',\n",
    "                         'None'       : 'unpaired'\n",
    "        }\n",
    "\n",
    "        first_line = {\"paired_status\": PAIRED_STATUS[str(is_paired)]}\n",
    "        \n",
    "\n",
    "        out1 = \"The weighted-average {paired_status} mean differences \".format(**first_line)\n",
    "        \n",
    "        base_string_fmt = \"{:.\" + str(sigfig) + \"}\"\n",
    "        if \".\" in str(self.__ci):\n",
    "            ci_width = base_string_fmt.format(self.__ci)\n",
    "        else:\n",
    "            ci_width = str(self.__ci)\n",
    "        \n",
    "        ci_out = {\"es\"       : base_string_fmt.format(self.__difference),\n",
    "                  \"ci\"       : ci_width,\n",
    "                  \"bca_low\"  : base_string_fmt.format(self.__bca_low),\n",
    "                  \"bca_high\" : base_string_fmt.format(self.__bca_high)}\n",
    "        \n",
    "        out2 = \"is {es} [{ci}%CI {bca_low}, {bca_high}].\".format(**ci_out)\n",
    "        out = out1 + out2\n",
    "\n",
    "        if header is True:\n",
    "            out = print_greeting() + \"\\n\" + \"\\n\" + out\n",
    "\n",
    "\n",
    "        pval_rounded = base_string_fmt.format(self.pvalue_permutation)\n",
    "\n",
    "        \n",
    "        p1 = \"The p-value of the two-sided permutation t-test is {}, \".format(pval_rounded)\n",
    "        p2 = \"calculated for legacy purposes only. \"\n",
    "        pvalue = p1 + p2\n",
    "\n",
    "\n",
    "        bs1 = \"{} bootstrap samples were taken; \".format(self.__resamples)\n",
    "        bs2 = \"the confidence interval is bias-corrected and accelerated.\"\n",
    "        bs = bs1 + bs2\n",
    "\n",
    "        pval_def1 = \"Any p-value reported is the probability of observing the\" + \\\n",
    "                    \"effect size (or greater),\\nassuming the null hypothesis of\" + \\\n",
    "                    \"zero difference is true.\"\n",
    "        pval_def2 = \"\\nFor each p-value, 5000 reshuffles of the \" + \\\n",
    "                    \"control and test labels were performed.\"\n",
    "        pval_def = pval_def1 + pval_def2\n",
    "\n",
    "\n",
    "        return \"{}\\n{}\\n\\n{}\\n{}\".format(out, pvalue, bs, pval_def)\n",
    "\n",
    "\n",
    "    def to_dict(self):\n",
    "        \"\"\"\n",
    "        Returns the attributes of the `dabest.MiniMetaDelta` object as a\n",
    "        dictionary.\n",
    "        \"\"\"\n",
    "        # Only get public (user-facing) attributes.\n",
    "        attrs = [a for a in dir(self)\n",
    "                 if not a.startswith((\"_\", \"to_dict\"))]\n",
    "        out = {}\n",
    "        for a in attrs:\n",
    "            out[a] = getattr(self, a)\n",
    "        return out\n",
    "\n",
    "\n",
    "    @property\n",
    "    def ci(self):\n",
    "        return self.__ci\n",
    "\n",
    "\n",
    "    @property\n",
    "    def alpha(self):\n",
    "        return self.__alpha\n",
    "\n",
    "\n",
    "    @property\n",
    "    def bias_correction(self):\n",
    "        return self.__bias_correction\n",
    "\n",
    "\n",
    "    @property\n",
    "    def bootstraps(self):\n",
    "        '''\n",
    "        Return the bootstrapped deltas from all the experiment groups.\n",
    "        '''\n",
    "        return self.__bootstraps\n",
    "\n",
    "\n",
    "    @property\n",
    "    def jackknives(self):\n",
    "        return self.__jackknives\n",
    "\n",
    "\n",
    "    @property\n",
    "    def acceleration_value(self):\n",
    "        return self.__acceleration_value\n",
    "\n",
    "\n",
    "    @property\n",
    "    def bca_low(self):\n",
    "        return self.__bca_low\n",
    "\n",
    "\n",
    "    @property\n",
    "    def bca_high(self):\n",
    "        return self.__bca_high\n",
    "\n",
    "\n",
    "    @property\n",
    "    def bca_interval_idx(self):\n",
    "        return self.__bca_interval_idx\n",
    "\n",
    "\n",
    "    @property\n",
    "    def control(self):\n",
    "        '''\n",
    "        Return the names of the control groups from all the experiment \n",
    "        groups in order.\n",
    "        '''\n",
    "        return self.__control\n",
    "\n",
    "\n",
    "    @property\n",
    "    def test(self):\n",
    "        '''\n",
    "        Return the names of the test groups from all the experiment \n",
    "        groups in order.\n",
    "        '''\n",
    "        return self.__test\n",
    "    \n",
    "    @property\n",
    "    def control_N(self):\n",
    "        '''\n",
    "        Return the sizes of the control groups from all the experiment \n",
    "        groups in order.\n",
    "        '''\n",
    "        return self.__control_N\n",
    "\n",
    "\n",
    "    @property\n",
    "    def test_N(self):\n",
    "        '''\n",
    "        Return the sizes of the test groups from all the experiment \n",
    "        groups in order.\n",
    "        '''\n",
    "        return self.__test_N\n",
    "\n",
    "\n",
    "    @property\n",
    "    def control_var(self):\n",
    "        '''\n",
    "        Return the estimated population variances of the control groups \n",
    "        from all the experiment groups in order. Here the population \n",
    "        variance is estimated from the sample variance. \n",
    "        '''\n",
    "        return self.__control_var\n",
    "\n",
    "\n",
    "    @property\n",
    "    def test_var(self):\n",
    "        '''\n",
    "        Return the estimated population variances of the control groups \n",
    "        from all the experiment groups in order. Here the population \n",
    "        variance is estimated from the sample variance. \n",
    "        '''\n",
    "        return self.__test_var\n",
    "\n",
    "    \n",
    "    @property\n",
    "    def group_var(self):\n",
    "        '''\n",
    "        Return the pooled group variances of all the experiment groups \n",
    "        in order. \n",
    "        '''\n",
    "        return self.__group_var\n",
    "\n",
    "\n",
    "    @property\n",
    "    def bootstraps_weighted_delta(self):\n",
    "        '''\n",
    "        Return the weighted-average mean differences calculated from the bootstrapped \n",
    "        deltas and weights across the experiment groups, where the weights are \n",
    "        the inverse of the pooled group variances.\n",
    "        '''\n",
    "        return self.__bootstraps_weighted_delta\n",
    "\n",
    "\n",
    "    @property\n",
    "    def difference(self):\n",
    "        '''\n",
    "        Return the weighted-average delta calculated from the raw data.\n",
    "        '''\n",
    "        return self.__difference\n",
    "\n",
    "\n",
    "    @property\n",
    "    def pct_interval_idx (self):\n",
    "        return self.__pct_interval_idx \n",
    "\n",
    "\n",
    "    @property\n",
    "    def pct_low(self):\n",
    "        return self.__pct_low\n",
    "\n",
    "\n",
    "    @property\n",
    "    def pct_high(self):\n",
    "        return self.__pct_high\n",
    "\n",
    "\n",
    "    @property\n",
    "    def pvalue_permutation(self):\n",
    "        try:\n",
    "            return self.__pvalue_permutation\n",
    "        except AttributeError:\n",
    "            self.__permutation_test()\n",
    "            return self.__pvalue_permutation\n",
    "    \n",
    "\n",
    "    @property\n",
    "    def permutation_count(self):\n",
    "        return self.__permutation_count\n",
    "\n",
    "    \n",
    "    @property\n",
    "    def permutations(self):\n",
    "        '''\n",
    "        Return the mean differences of permutations obtained during\n",
    "        the permutation test for each experiment group.\n",
    "        '''\n",
    "        try:\n",
    "            return self.__permutations\n",
    "        except AttributeError:\n",
    "            self.__permutation_test()\n",
    "            return self.__permutations\n",
    "\n",
    "\n",
    "    @property\n",
    "    def permutations_var(self):\n",
    "        '''\n",
    "        Return the pooled group variances of permutations obtained during\n",
    "        the permutation test for each experiment group.\n",
    "        '''\n",
    "        try:\n",
    "            return self.__permutations_var\n",
    "        except AttributeError:\n",
    "            self.__permutation_test()\n",
    "            return self.__permutations_var\n",
    "\n",
    "    \n",
    "    @property\n",
    "    def permutations_weighted_delta(self):\n",
    "        '''\n",
    "        Return the weighted-average deltas of permutations obtained \n",
    "        during the permutation test.\n",
    "        '''\n",
    "        try:\n",
    "            return self.__permutations_weighted_delta\n",
    "        except AttributeError:\n",
    "            self.__permutation_test()\n",
    "            return self.__permutations_weighted_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3460656c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def two_group_difference(control, test, is_paired=False,\n",
    "                        effect_size=\"mean_diff\"):\n",
    "    \"\"\"\n",
    "    Computes the following metrics for control and test:\n",
    "        - Unstandardized mean difference\n",
    "        - Standardized mean differences (paired or unpaired)\n",
    "            * Cohen's d\n",
    "            * Hedges' g\n",
    "        - Median difference\n",
    "        - Cliff's Delta\n",
    "        - Cohen's h (distance between two proportions)\n",
    "\n",
    "    See the Wikipedia entry here: https://bit.ly/2LzWokf\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    control, test: list, tuple, or ndarray.\n",
    "        Accepts lists, tuples, or numpy ndarrays of numeric types.\n",
    "\n",
    "    is_paired: boolean, default False.\n",
    "        If True, returns the paired Cohen's d.\n",
    "\n",
    "    effect_size: string, default \"mean_diff\"\n",
    "        Any one of the following effect sizes:\n",
    "        [\"mean_diff\", \"median_diff\", \"cohens_d\", \"hedges_g\", \"cliffs_delta\"]\n",
    "\n",
    "        mean_diff:      This is simply the mean of `control` subtracted from\n",
    "                        the mean of `test`.\n",
    "\n",
    "        cohens_d:       This is the mean of control subtracted from the\n",
    "                        mean of test, divided by the pooled standard deviation\n",
    "                        of control and test. The pooled SD is the square as:\n",
    "\n",
    "\n",
    "                               (n1 - 1) * var(control) + (n2 - 1) * var(test)\n",
    "                        sqrt (   -------------------------------------------  )\n",
    "                                                 (n1 + n2 - 2)\n",
    "\n",
    "                        where n1 and n2 are the sizes of control and test\n",
    "                        respectively.\n",
    "\n",
    "        hedges_g:       This is Cohen's d corrected for bias via multiplication\n",
    "                         with the following correction factor:\n",
    "\n",
    "                                        gamma(n/2)\n",
    "                        J(n) = ------------------------------\n",
    "                               sqrt(n/2) * gamma((n - 1) / 2)\n",
    "\n",
    "                        where n = (n1 + n2 - 2).\n",
    "\n",
    "        median_diff:    This is the median of `control` subtracted from the\n",
    "                        median of `test`.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        float: The desired effect size.\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "\n",
    "    if effect_size == \"mean_diff\":\n",
    "        return func_difference(control, test, np.mean, is_paired)\n",
    "\n",
    "    elif effect_size == \"median_diff\":\n",
    "        return func_difference(control, test, np.median, is_paired)\n",
    "\n",
    "    elif effect_size == \"cohens_d\":\n",
    "        return cohens_d(control, test, is_paired)\n",
    "\n",
    "    elif effect_size == \"cohens_h\":\n",
    "        return cohens_h(control, test)\n",
    "\n",
    "    elif effect_size == \"hedges_g\":\n",
    "        return hedges_g(control, test, is_paired)\n",
    "\n",
    "    elif effect_size == \"cliffs_delta\":\n",
    "        if is_paired is True:\n",
    "            err1 = \"`is_paired` is True; therefore Cliff's delta is not defined.\"\n",
    "            raise ValueError(err1)\n",
    "        else:\n",
    "            return cliffs_delta(control, test)\n",
    "        \n",
    "def calculate_group_var(control_var, control_N,test_var, test_N):\n",
    "    return control_var/control_N + test_var/test_N\n",
    "\n",
    "def func_difference(control, test, func, is_paired):\n",
    "    \"\"\"\n",
    "    Applies func to `control` and `test`, and then returns the difference.\n",
    "\n",
    "    Keywords:\n",
    "    --------\n",
    "        control, test: List, tuple, or array.\n",
    "            NaNs are automatically discarded.\n",
    "\n",
    "        func: summary function to apply.\n",
    "\n",
    "        is_paired: boolean.\n",
    "            If True, computes func(test - control).\n",
    "            If False, computes func(test) - func(control).\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "        diff: float.\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "\n",
    "    # Convert to numpy arrays for speed.\n",
    "    # NaNs are automatically dropped.\n",
    "    if control.__class__ != np.ndarray:\n",
    "        control = np.array(control)\n",
    "    if test.__class__ != np.ndarray:\n",
    "        test    = np.array(test)\n",
    "\n",
    "    if is_paired:\n",
    "        if len(control) != len(test):\n",
    "            err = \"The two arrays supplied do not have the same length.\"\n",
    "            raise ValueError(err)\n",
    "\n",
    "        control_nan = np.where(np.isnan(control))[0]\n",
    "        test_nan    = np.where(np.isnan(test))[0]\n",
    "\n",
    "        indexes_to_drop = np.unique(np.concatenate([control_nan,\n",
    "                                                    test_nan]))\n",
    "\n",
    "        good_indexes = [i for i in range(0, len(control))\n",
    "                        if i not in indexes_to_drop]\n",
    "\n",
    "        control = control[good_indexes]\n",
    "        test    = test[good_indexes]\n",
    "\n",
    "        return func(test - control)\n",
    "\n",
    "    else:\n",
    "        control = control[~np.isnan(control)]\n",
    "        test    = test[~np.isnan(test)]\n",
    "        return func(test) - func(control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53139dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class TwoGroupsEffectSize(object):\n",
    "\n",
    "    \"\"\"\n",
    "    A class to compute and store the results of bootstrapped\n",
    "    mean differences between two groups.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, control, test, effect_size,proportional,\n",
    "                 is_paired=None, ci=95,\n",
    "                 resamples=5000, \n",
    "                 permutation_count=5000, \n",
    "                 random_seed=12345):\n",
    "\n",
    "        \"\"\"\n",
    "        Compute the effect size between two groups.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        control : array-like\n",
    "        test : array-like\n",
    "            These should be numerical iterables.\n",
    "        effect_size : string.\n",
    "            Any one of the following are accepted inputs:\n",
    "            'mean_diff', 'median_diff', 'cohens_d', 'hedges_g', or 'cliffs_delta'\n",
    "        is_paired : string, default None\n",
    "        resamples : int, default 5000\n",
    "            The number of bootstrap resamples to be taken for the calculation\n",
    "            of the confidence interval limits.\n",
    "        permutation_count : int, default 5000\n",
    "            The number of permutations (reshuffles) to perform for the \n",
    "            computation of the permutation p-value\n",
    "        ci : float, default 95\n",
    "            The confidence interval width. The default of 95 produces 95%\n",
    "            confidence intervals.\n",
    "        random_seed : int, default 12345\n",
    "            `random_seed` is used to seed the random number generator during\n",
    "            bootstrap resampling. This ensures that the confidence intervals\n",
    "            reported are replicable.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        A :py:class:`TwoGroupEffectSize` object.\n",
    "        \n",
    "        difference : float\n",
    "            The effect size of the difference between the control and the test.\n",
    "        \n",
    "        effect_size : string\n",
    "            The type of effect size reported.\n",
    "        \n",
    "        is_paired : string\n",
    "            The type of repeated-measures experiment.\n",
    "            \n",
    "        ci : float\n",
    "            Returns the width of the confidence interval, in percent.\n",
    "            \n",
    "        alpha : float\n",
    "            Returns the significance level of the statistical test as a float\n",
    "            between 0 and 1.\n",
    "            \n",
    "        resamples : int\n",
    "            The number of resamples performed during the bootstrap procedure.\n",
    "\n",
    "        bootstraps : numpy ndarray\n",
    "            The generated bootstraps of the effect size.\n",
    "            \n",
    "        random_seed : int\n",
    "            The number used to initialise the numpy random seed generator, ie.\n",
    "            `seed_value` from `numpy.random.seed(seed_value)` is returned.\n",
    "            \n",
    "        bca_low, bca_high : float\n",
    "            The bias-corrected and accelerated confidence interval lower limit\n",
    "            and upper limits, respectively.\n",
    "            \n",
    "        pct_low, pct_high : float\n",
    "            The percentile confidence interval lower limit and upper limits, \n",
    "            respectively.\n",
    "            \n",
    "            \n",
    "        Examples\n",
    "        --------\n",
    "        >>> import numpy as np\n",
    "        >>> from scipy.stats import norm\n",
    "        >>> import dabest\n",
    "        >>> np.random.seed(12345)\n",
    "        >>> control = norm.rvs(loc=0, size=30)\n",
    "        >>> test = norm.rvs(loc=0.5, size=30)\n",
    "        >>> effsize = dabest.TwoGroupsEffectSize(control, test, \"mean_diff\")\n",
    "        >>> effsize\n",
    "        The unpaired mean difference is -0.253 [95%CI -0.78, 0.25].\n",
    "        The p-value of the two-sided permutation t-test is 0.348, calculated \n",
    "        for legacy purposes only. \n",
    "\n",
    "        5000 bootstrap samples were taken; the confidence interval is \n",
    "        bias-corrected and accelerated. The p-value(s) reported are the \n",
    "        likelihood(s) of observing the effect size(s), if the null hypothesis \n",
    "        of zero difference is true. For each p-value, 5000 reshuffles of the \n",
    "        control and test labels were performed.\n",
    "        >>> effsize.to_dict() \n",
    "        {'alpha': 0.05,\n",
    "         'bca_high': 0.24951887238295106,\n",
    "         'bca_interval_idx': (125, 4875),\n",
    "         'bca_low': -0.7801782111071534,\n",
    "         'bootstraps': array([-0.3649424 , -0.45018155, -0.56034412, ..., -0.49805581,\n",
    "                              -0.25334475, -0.55206229]),\n",
    "         'ci': 95,\n",
    "         'difference': -0.25315417702752846,\n",
    "         'effect_size': 'mean difference',\n",
    "         'is_paired': None,\n",
    "         'pct_high': 0.24951887238295106,\n",
    "         'pct_interval_idx': (125, 4875),\n",
    "         'pct_low': -0.7801782111071534,\n",
    "         'permutation_count': 5000,\n",
    "         'permutations': array([ 0.17221029,  0.03112419, -0.13911387, ..., -0.38007941,\n",
    "                                 0.30261507, -0.09073054]),\n",
    "         'permutations_var': array([0.07201642, 0.07251104, 0.07219407, ..., 0.07003705, 0.07094885,\n",
    "                                 0.07238581]),\n",
    "         'pvalue_brunner_munzel': nan,\n",
    "         'pvalue_kruskal': nan,\n",
    "         'pvalue_mann_whitney': 0.5201446121616038,\n",
    "         'pvalue_paired_students_t': nan,\n",
    "         'pvalue_permutation': 0.3484,\n",
    "         'pvalue_students_t': 0.34743913903372836,\n",
    "         'pvalue_welch': 0.3474493875548965,\n",
    "         'pvalue_wilcoxon': nan,\n",
    "         'random_seed': 12345,\n",
    "         'resamples': 5000,\n",
    "         'statistic_brunner_munzel': nan,\n",
    "         'statistic_kruskal': nan,\n",
    "         'statistic_mann_whitney': 494.0,\n",
    "         'statistic_paired_students_t': nan,\n",
    "         'statistic_students_t': 0.9472545159069105,\n",
    "         'statistic_welch': 0.9472545159069105,\n",
    "         'statistic_wilcoxon': nan}\n",
    "        \"\"\"\n",
    "        \n",
    "        import numpy as np\n",
    "        from numpy import array, isnan, isinf\n",
    "        from numpy import sort as npsort\n",
    "        from numpy.random import choice, seed\n",
    "\n",
    "        import scipy.stats as spstats\n",
    "\n",
    "        # import statsmodels.stats.power as power\n",
    "\n",
    "        from string import Template\n",
    "        import warnings\n",
    "\n",
    "#         from ._stats_tools import confint_2group_diff as ci2g\n",
    "#         from ._stats_tools import effsize as es\n",
    "\n",
    "\n",
    "        self.__EFFECT_SIZE_DICT =  {\"mean_diff\" : \"mean difference\",\n",
    "                                    \"median_diff\" : \"median difference\",\n",
    "                                    \"cohens_d\" : \"Cohen's d\",\n",
    "                                    \"cohens_h\" : \"Cohen's h\",\n",
    "                                    \"hedges_g\" : \"Hedges' g\",\n",
    "                                    \"cliffs_delta\" : \"Cliff's delta\"}\n",
    "\n",
    "\n",
    "        kosher_es = [a for a in self.__EFFECT_SIZE_DICT.keys()]\n",
    "        if effect_size not in kosher_es:\n",
    "            merr1 = \"The effect size '{}'\".format(effect_size)\n",
    "            err2 = \"is not one of {}\".format(kosher_es)\n",
    "            raise ValueError(\" \".join([err1, err2]))\n",
    "\n",
    "        if effect_size == \"cliffs_delta\" and is_paired:\n",
    "            err1 = \"`paired` is not None; therefore Cliff's delta is not defined.\"\n",
    "            raise ValueError(err1)\n",
    "\n",
    "        if proportional==True and effect_size not in ['mean_diff','cohens_h']:\n",
    "            err1 = \"`proportional` is True; therefore effect size other than mean_diff and cohens_h is not defined.\"\n",
    "            raise ValueError(err1)\n",
    "\n",
    "        if proportional==True and (np.isin(control, [0, 1]).all() == False or np.isin(test, [0, 1]).all() == False):\n",
    "            err1 = \"`proportional` is True; Only accept binary data consisting of 0 and 1.\"\n",
    "            raise ValueError(err1)\n",
    "\n",
    "        # Convert to numpy arrays for speed.\n",
    "        # NaNs are automatically dropped.\n",
    "        control = array(control)\n",
    "        test    = array(test)\n",
    "        control = control[~isnan(control)]\n",
    "        test    = test[~isnan(test)]\n",
    "\n",
    "        self.__effect_size       = effect_size\n",
    "        self.__control           = control\n",
    "        self.__test              = test\n",
    "        self.__is_paired         = is_paired\n",
    "        self.__resamples         = resamples\n",
    "        self.__permutation_count = permutation_count\n",
    "        self.__random_seed       = random_seed\n",
    "        self.__ci                = ci\n",
    "        self.__alpha             = _compute_alpha_from_ci(ci)\n",
    "\n",
    "        self.__difference = two_group_difference(\n",
    "                                control, test, is_paired, effect_size)\n",
    "        \n",
    "        self.__jackknives = compute_meandiff_jackknife(\n",
    "                                control, test, is_paired, effect_size)\n",
    "\n",
    "        self.__acceleration_value = _calc_accel(self.__jackknives)\n",
    "\n",
    "        bootstraps = compute_bootstrapped_diff(\n",
    "                            control, test, is_paired, effect_size,\n",
    "                            resamples, random_seed)\n",
    "        self.__bootstraps = bootstraps\n",
    "        \n",
    "        sorted_bootstraps = npsort(self.__bootstraps)\n",
    "        # Added in v0.2.6.\n",
    "        # Raises a UserWarning if there are any infiinities in the bootstraps.\n",
    "        num_infinities = len(self.__bootstraps[isinf(self.__bootstraps)])\n",
    "        \n",
    "        if num_infinities > 0:\n",
    "            warn_msg = \"There are {} bootstrap(s) that are not defined. \"\\\n",
    "            \"This is likely due to smaple sample sizes. \"\\\n",
    "            \"The values in a bootstrap for a group will be more likely \"\\\n",
    "            \"to be all equal, with a resulting variance of zero. \"\\\n",
    "            \"The computation of Cohen's d and Hedges' g thus \"\\\n",
    "            \"involved a division by zero. \"\n",
    "            warnings.warn(warn_msg.format(num_infinities), \n",
    "                          category=UserWarning)\n",
    "\n",
    "        self.__bias_correction = compute_meandiff_bias_correction(\n",
    "                                    self.__bootstraps, self.__difference)\n",
    "\n",
    "        # Compute BCa intervals.\n",
    "        bca_idx_low, bca_idx_high = compute_interval_limits(\n",
    "            self.__bias_correction, self.__acceleration_value,\n",
    "            self.__resamples, ci)\n",
    "\n",
    "        self.__bca_interval_idx = (bca_idx_low, bca_idx_high)\n",
    "\n",
    "        if ~isnan(bca_idx_low) and ~isnan(bca_idx_high):\n",
    "            self.__bca_low  = sorted_bootstraps[bca_idx_low]\n",
    "            self.__bca_high = sorted_bootstraps[bca_idx_high]\n",
    "\n",
    "            err1 = \"The $lim_type limit of the interval\"\n",
    "            err2 = \"was in the $loc 10 values.\"\n",
    "            err3 = \"The result should be considered unstable.\"\n",
    "            err_temp = Template(\" \".join([err1, err2, err3]))\n",
    "\n",
    "            if bca_idx_low <= 10:\n",
    "                warnings.warn(err_temp.substitute(lim_type=\"lower\",\n",
    "                                                  loc=\"bottom\"),\n",
    "                              stacklevel=1)\n",
    "\n",
    "            if bca_idx_high >= resamples-9:\n",
    "                warnings.warn(err_temp.substitute(lim_type=\"upper\",\n",
    "                                                  loc=\"top\"),\n",
    "                              stacklevel=1)\n",
    "\n",
    "        else:\n",
    "            err1 = \"The $lim_type limit of the BCa interval cannot be computed.\"\n",
    "            err2 = \"It is set to the effect size itself.\"\n",
    "            err3 = \"All bootstrap values were likely all the same.\"\n",
    "            err_temp = Template(\" \".join([err1, err2, err3]))\n",
    "\n",
    "            if isnan(bca_idx_low):\n",
    "                self.__bca_low  = self.__difference\n",
    "                warnings.warn(err_temp.substitute(lim_type=\"lower\"),\n",
    "                              stacklevel=0)\n",
    "\n",
    "            if isnan(bca_idx_high):\n",
    "                self.__bca_high  = self.__difference\n",
    "                warnings.warn(err_temp.substitute(lim_type=\"upper\"),\n",
    "                              stacklevel=0)\n",
    "\n",
    "        # Compute percentile intervals.\n",
    "        pct_idx_low  = int((self.__alpha/2)     * resamples)\n",
    "        pct_idx_high = int((1-(self.__alpha/2)) * resamples)\n",
    "\n",
    "        self.__pct_interval_idx = (pct_idx_low, pct_idx_high)\n",
    "        self.__pct_low  = sorted_bootstraps[pct_idx_low]\n",
    "        self.__pct_high = sorted_bootstraps[pct_idx_high]\n",
    "\n",
    "        # Perform statistical tests.\n",
    "                \n",
    "        self.__PermutationTest_result = PermutationTest(control, test, \n",
    "                                                        effect_size, \n",
    "                                                        is_paired,\n",
    "                                                        permutation_count)\n",
    "        \n",
    "        if is_paired:\n",
    "            # Wilcoxon, a non-parametric version of the paired T-test.\n",
    "            wilcoxon = spstats.wilcoxon(control, test)\n",
    "            self.__pvalue_wilcoxon = wilcoxon.pvalue\n",
    "            self.__statistic_wilcoxon = wilcoxon.statistic\n",
    "            \n",
    "            \n",
    "            # Introduced in v0.2.8, removed in v0.3.0 for performance issues.\n",
    "#             lqrt_result = lqrt.lqrtest_rel(control, test, \n",
    "#                                     random_state=random_seed)\n",
    "#             self.__pvalue_paired_lqrt = lqrt_result.pvalue\n",
    "#             self.__statistic_paired_lqrt = lqrt_result.statistic\n",
    "\n",
    "            if effect_size != \"median_diff\":\n",
    "                # Paired Student's t-test.\n",
    "                paired_t = spstats.ttest_rel(control, test, nan_policy='omit')\n",
    "                self.__pvalue_paired_students_t = paired_t.pvalue\n",
    "                self.__statistic_paired_students_t = paired_t.statistic\n",
    "\n",
    "                standardized_es = cohens_d(control, test, is_paired)\n",
    "                # self.__power = power.tt_solve_power(standardized_es,\n",
    "                #                                     len(control),\n",
    "                #                                     alpha=self.__alpha)\n",
    "\n",
    "\n",
    "        elif effect_size == \"cliffs_delta\":\n",
    "            # Let's go with Brunner-Munzel!\n",
    "            brunner_munzel = spstats.brunnermunzel(control, test,\n",
    "                                                     nan_policy='omit')\n",
    "            self.__pvalue_brunner_munzel = brunner_munzel.pvalue\n",
    "            self.__statistic_brunner_munzel = brunner_munzel.statistic\n",
    "\n",
    "\n",
    "        elif effect_size == \"median_diff\":\n",
    "            # According to scipy's documentation of the function,\n",
    "            # \"The Kruskal-Wallis H-test tests the null hypothesis\n",
    "            # that the population median of all of the groups are equal.\"\n",
    "            kruskal = spstats.kruskal(control, test, nan_policy='omit')\n",
    "            self.__pvalue_kruskal = kruskal.pvalue\n",
    "            self.__statistic_kruskal = kruskal.statistic\n",
    "            # self.__power = np.nan\n",
    "\n",
    "        else: # for mean difference, Cohen's d, and Hedges' g.\n",
    "            # Welch's t-test, assumes normality of distributions,\n",
    "            # but does not assume equal variances.\n",
    "            welch = spstats.ttest_ind(control, test, equal_var=False,\n",
    "                                       nan_policy='omit')\n",
    "            self.__pvalue_welch = welch.pvalue\n",
    "            self.__statistic_welch = welch.statistic\n",
    "\n",
    "            # Student's t-test, assumes normality of distributions,\n",
    "            # as well as assumption of equal variances.\n",
    "            students_t = spstats.ttest_ind(control, test, equal_var=True,\n",
    "                                            nan_policy='omit')\n",
    "            self.__pvalue_students_t = students_t.pvalue\n",
    "            self.__statistic_students_t = students_t.statistic\n",
    "\n",
    "            # Mann-Whitney test: Non parametric,\n",
    "            # does not assume normality of distributions\n",
    "            try:\n",
    "                mann_whitney = spstats.mannwhitneyu(control, test, \n",
    "                                                    alternative='two-sided')\n",
    "                self.__pvalue_mann_whitney = mann_whitney.pvalue\n",
    "                self.__statistic_mann_whitney = mann_whitney.statistic\n",
    "            except ValueError:\n",
    "                # Occurs when the control and test are exactly identical\n",
    "                # in terms of rank (eg. all zeros.)\n",
    "                pass\n",
    "            \n",
    "            # Introduced in v0.2.8, removed in v0.3.0 for performance issues.\n",
    "#             # Likelihood Q-Ratio test:\n",
    "#             lqrt_equal_var_result = lqrt.lqrtest_ind(control, test, \n",
    "#                                         random_state=random_seed,\n",
    "#                                         equal_var=True)\n",
    "                            \n",
    "#             self.__pvalue_lqrt_equal_var = lqrt_equal_var_result.pvalue\n",
    "#             self.__statistic_lqrt_equal_var = lqrt_equal_var_result.statistic\n",
    "            \n",
    "#             lqrt_unequal_var_result = lqrt.lqrtest_ind(control, test, \n",
    "#                                         random_state=random_seed,\n",
    "#                                         equal_var=False)\n",
    "                                        \n",
    "#             self.__pvalue_lqrt_unequal_var = lqrt_unequal_var_result.pvalue\n",
    "#             self.__statistic_lqrt_unequal_var = lqrt_unequal_var_result.statistic\n",
    "                    \n",
    "\n",
    "            standardized_es = cohens_d(control, test, is_paired = None)\n",
    "            \n",
    "            # The Cohen's h calculation is for binary categorical data\n",
    "            try:\n",
    "                self.__proportional_difference = cohens_h(control, test)\n",
    "            except ValueError:\n",
    "                # Occur only when the data consists not only 0's and 1's.\n",
    "                pass\n",
    "            # self.__power = power.tt_ind_solve_power(standardized_es,\n",
    "            #                                         len(control),\n",
    "            #                                         alpha=self.__alpha,\n",
    "            #                                         ratio=len(test)/len(control)\n",
    "            #                                         )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def __repr__(self, show_resample_count=True, define_pval=True, sigfig=3):\n",
    "        \n",
    "        # # Deprecated in v0.3.0; permutation p-values will be reported by default.\n",
    "        # UNPAIRED_ES_TO_TEST = {\"mean_diff\"    : \"Mann-Whitney\",\n",
    "        #                        \"median_diff\"  : \"Kruskal\",\n",
    "        #                        \"cohens_d\"     : \"Mann-Whitney\",\n",
    "        #                        \"hedges_g\"     : \"Mann-Whitney\",\n",
    "        #                        \"cliffs_delta\" : \"Brunner-Munzel\"}\n",
    "        # \n",
    "        # TEST_TO_PVAL_ATTR = {\"Mann-Whitney\"    : \"pvalue_mann_whitney\",\n",
    "        #                      \"Kruskal\"        :  \"pvalue_kruskal\",\n",
    "        #                      \"Brunner-Munzel\" :  \"pvalue_brunner_munzel\",\n",
    "        #                      \"Wilcoxon\"       :  \"pvalue_wilcoxon\"}\n",
    "        \n",
    "        RM_STATUS = {'baseline'  : 'for repeated measures against baseline \\n', \n",
    "                     'sequential': 'for the sequential design of repeated-measures experiment \\n',\n",
    "                     'None'      : ''\n",
    "                    }\n",
    "\n",
    "        PAIRED_STATUS = {'baseline'   : 'paired', \n",
    "                         'sequential' : 'paired',\n",
    "                         'None'       : 'unpaired'\n",
    "        }\n",
    "\n",
    "        first_line = {\"rm_status\"    : RM_STATUS[str(self.__is_paired)],\n",
    "                      \"es\"           : self.__EFFECT_SIZE_DICT[self.__effect_size],\n",
    "                      \"paired_status\": PAIRED_STATUS[str(self.__is_paired)]}\n",
    "        \n",
    "\n",
    "        out1 = \"The {paired_status} {es} {rm_status}\".format(**first_line)\n",
    "        \n",
    "        base_string_fmt = \"{:.\" + str(sigfig) + \"}\"\n",
    "        if \".\" in str(self.__ci):\n",
    "            ci_width = base_string_fmt.format(self.__ci)\n",
    "        else:\n",
    "            ci_width = str(self.__ci)\n",
    "        \n",
    "        ci_out = {\"es\"       : base_string_fmt.format(self.__difference),\n",
    "                  \"ci\"       : ci_width,\n",
    "                  \"bca_low\"  : base_string_fmt.format(self.__bca_low),\n",
    "                  \"bca_high\" : base_string_fmt.format(self.__bca_high)}\n",
    "        \n",
    "        out2 = \"is {es} [{ci}%CI {bca_low}, {bca_high}].\".format(**ci_out)\n",
    "        out = out1 + out2\n",
    "        \n",
    "        # # Deprecated in v0.3.0; permutation p-values will be reported by default.\n",
    "        # if self.__is_paired:\n",
    "        #     stats_test = \"Wilcoxon\"\n",
    "        # else:\n",
    "        #     stats_test = UNPAIRED_ES_TO_TEST[self.__effect_size]\n",
    "        \n",
    "        \n",
    "        # pval_rounded = base_string_fmt.format(getattr(self,\n",
    "        #                                              TEST_TO_PVAL_ATTR[stats_test])\n",
    "        #                                       )\n",
    "        \n",
    "        pval_rounded = base_string_fmt.format(self.pvalue_permutation)\n",
    "        \n",
    "        # # Deprecated in v0.3.0; permutation p-values will be reported by default.\n",
    "        # pvalue = \"The two-sided p-value of the {} test is {}.\".format(stats_test,\n",
    "        #                                                         pval_rounded)\n",
    "        \n",
    "        # pvalue = \"The two-sided p-value of the {} test is {}.\".format(stats_test,\n",
    "        #                                                         pval_rounded)\n",
    "        \n",
    "        \n",
    "        p1 = \"The p-value of the two-sided permutation t-test is {}, \".format(pval_rounded)\n",
    "        p2 = \"calculated for legacy purposes only. \"\n",
    "        pvalue = p1 + p2\n",
    "                                                                \n",
    "        bs1 = \"{} bootstrap samples were taken; \".format(self.__resamples)\n",
    "        bs2 = \"the confidence interval is bias-corrected and accelerated.\"\n",
    "        bs = bs1 + bs2\n",
    "\n",
    "        pval_def1 = \"Any p-value reported is the probability of observing the\" + \\\n",
    "                    \"effect size (or greater),\\nassuming the null hypothesis of\" + \\\n",
    "                    \"zero difference is true.\"\n",
    "        pval_def2 = \"\\nFor each p-value, 5000 reshuffles of the \" + \\\n",
    "                    \"control and test labels were performed.\"\n",
    "        pval_def = pval_def1 + pval_def2\n",
    "\n",
    "        if show_resample_count and define_pval:\n",
    "            return \"{}\\n{}\\n\\n{}\\n{}\".format(out, pvalue, bs, pval_def)\n",
    "        elif show_resample_count is False and define_pval is True:\n",
    "            return \"{}\\n{}\\n\\n{}\".format(out, pvalue, pval_def)\n",
    "        elif show_resample_count is True and define_pval is False:\n",
    "            return \"{}\\n{}\\n\\n{}\".format(out, pvalue, bs)\n",
    "        else:\n",
    "            return \"{}\\n{}\".format(out, pvalue)\n",
    "\n",
    "\n",
    "\n",
    "    def to_dict(self):\n",
    "        \"\"\"\n",
    "        Returns the attributes of the `dabest.TwoGroupEffectSize` object as a\n",
    "        dictionary.\n",
    "        \"\"\"\n",
    "        # Only get public (user-facing) attributes.\n",
    "        attrs = [a for a in dir(self)\n",
    "                 if not a.startswith((\"_\", \"to_dict\"))]\n",
    "        out = {}\n",
    "        for a in attrs:\n",
    "            out[a] = getattr(self, a)\n",
    "        return out\n",
    "\n",
    "\n",
    "    @property\n",
    "    def difference(self):\n",
    "        \"\"\"\n",
    "        Returns the difference between the control and the test.\n",
    "        \"\"\"\n",
    "        return self.__difference\n",
    "\n",
    "    @property\n",
    "    def effect_size(self):\n",
    "        \"\"\"\n",
    "        Returns the type of effect size reported.\n",
    "        \"\"\"\n",
    "        return self.__EFFECT_SIZE_DICT[self.__effect_size]\n",
    "\n",
    "    @property\n",
    "    def is_paired(self):\n",
    "        return self.__is_paired\n",
    "\n",
    "    @property\n",
    "    def ci(self):\n",
    "        \"\"\"\n",
    "        Returns the width of the confidence interval, in percent.\n",
    "        \"\"\"\n",
    "        return self.__ci\n",
    "\n",
    "    @property\n",
    "    def alpha(self):\n",
    "        \"\"\"\n",
    "        Returns the significance level of the statistical test as a float\n",
    "        between 0 and 1.\n",
    "        \"\"\"\n",
    "        return self.__alpha\n",
    "\n",
    "    @property\n",
    "    def resamples(self):\n",
    "        \"\"\"\n",
    "        The number of resamples performed during the bootstrap procedure.\n",
    "        \"\"\"\n",
    "        return self.__resamples\n",
    "\n",
    "    @property\n",
    "    def bootstraps(self):\n",
    "        \"\"\"\n",
    "        The generated bootstraps of the effect size.\n",
    "        \"\"\"\n",
    "        return self.__bootstraps\n",
    "\n",
    "    @property\n",
    "    def random_seed(self):\n",
    "        \"\"\"\n",
    "        The number used to initialise the numpy random seed generator, ie.\n",
    "        `seed_value` from `numpy.random.seed(seed_value)` is returned.\n",
    "        \"\"\"\n",
    "        return self.__random_seed\n",
    "\n",
    "    @property\n",
    "    def bca_interval_idx(self):\n",
    "        return self.__bca_interval_idx\n",
    "\n",
    "    @property\n",
    "    def bca_low(self):\n",
    "        \"\"\"\n",
    "        The bias-corrected and accelerated confidence interval lower limit.\n",
    "        \"\"\"\n",
    "        return self.__bca_low\n",
    "\n",
    "    @property\n",
    "    def bca_high(self):\n",
    "        \"\"\"\n",
    "        The bias-corrected and accelerated confidence interval upper limit.\n",
    "        \"\"\"\n",
    "        return self.__bca_high\n",
    "\n",
    "    @property\n",
    "    def pct_interval_idx(self):\n",
    "        return self.__pct_interval_idx\n",
    "\n",
    "    @property\n",
    "    def pct_low(self):\n",
    "        \"\"\"\n",
    "        The percentile confidence interval lower limit.\n",
    "        \"\"\"\n",
    "        return self.__pct_low\n",
    "\n",
    "    @property\n",
    "    def pct_high(self):\n",
    "        \"\"\"\n",
    "        The percentile confidence interval lower limit.\n",
    "        \"\"\"\n",
    "        return self.__pct_high\n",
    "\n",
    "\n",
    "\n",
    "    @property\n",
    "    def pvalue_brunner_munzel(self):\n",
    "        from numpy import nan as npnan\n",
    "        try:\n",
    "            return self.__pvalue_brunner_munzel\n",
    "        except AttributeError:\n",
    "            return npnan\n",
    "\n",
    "    @property\n",
    "    def statistic_brunner_munzel(self):\n",
    "        from numpy import nan as npnan\n",
    "        try:\n",
    "            return self.__statistic_brunner_munzel\n",
    "        except AttributeError:\n",
    "            return npnan\n",
    "\n",
    "\n",
    "\n",
    "    @property\n",
    "    def pvalue_wilcoxon(self):\n",
    "        from numpy import nan as npnan\n",
    "        try:\n",
    "            return self.__pvalue_wilcoxon\n",
    "        except AttributeError:\n",
    "            return npnan\n",
    "\n",
    "    @property\n",
    "    def statistic_wilcoxon(self):\n",
    "        from numpy import nan as npnan\n",
    "        try:\n",
    "            return self.__statistic_wilcoxon\n",
    "        except AttributeError:\n",
    "            return npnan\n",
    "\n",
    "\n",
    "\n",
    "    @property\n",
    "    def pvalue_paired_students_t(self):\n",
    "        from numpy import nan as npnan\n",
    "        try:\n",
    "            return self.__pvalue_paired_students_t\n",
    "        except AttributeError:\n",
    "            return npnan\n",
    "\n",
    "    @property\n",
    "    def statistic_paired_students_t(self):\n",
    "        from numpy import nan as npnan\n",
    "        try:\n",
    "            return self.__statistic_paired_students_t\n",
    "        except AttributeError:\n",
    "            return npnan\n",
    "\n",
    "\n",
    "\n",
    "    @property\n",
    "    def pvalue_kruskal(self):\n",
    "        from numpy import nan as npnan\n",
    "        try:\n",
    "            return self.__pvalue_kruskal\n",
    "        except AttributeError:\n",
    "            return npnan\n",
    "\n",
    "    @property\n",
    "    def statistic_kruskal(self):\n",
    "        from numpy import nan as npnan\n",
    "        try:\n",
    "            return self.__statistic_kruskal\n",
    "        except AttributeError:\n",
    "            return npnan\n",
    "\n",
    "\n",
    "\n",
    "    @property\n",
    "    def pvalue_welch(self):\n",
    "        from numpy import nan as npnan\n",
    "        try:\n",
    "            return self.__pvalue_welch\n",
    "        except AttributeError:\n",
    "            return npnan\n",
    "\n",
    "    @property\n",
    "    def statistic_welch(self):\n",
    "        from numpy import nan as npnan\n",
    "        try:\n",
    "            return self.__statistic_welch\n",
    "        except AttributeError:\n",
    "            return npnan\n",
    "\n",
    "\n",
    "\n",
    "    @property\n",
    "    def pvalue_students_t(self):\n",
    "        from numpy import nan as npnan\n",
    "        try:\n",
    "            return self.__pvalue_students_t\n",
    "        except AttributeError:\n",
    "            return npnan\n",
    "\n",
    "    @property\n",
    "    def statistic_students_t(self):\n",
    "        from numpy import nan as npnan\n",
    "        try:\n",
    "            return self.__statistic_students_t\n",
    "        except AttributeError:\n",
    "            return npnan\n",
    "\n",
    "\n",
    "\n",
    "    @property\n",
    "    def pvalue_mann_whitney(self):\n",
    "        from numpy import nan as npnan\n",
    "        try:\n",
    "            return self.__pvalue_mann_whitney\n",
    "        except AttributeError:\n",
    "            return npnan\n",
    "\n",
    "\n",
    "\n",
    "    @property\n",
    "    def statistic_mann_whitney(self):\n",
    "        from numpy import nan as npnan\n",
    "        try:\n",
    "            return self.__statistic_mann_whitney\n",
    "        except AttributeError:\n",
    "            return npnan\n",
    "            \n",
    "    # Introduced in v0.3.0.\n",
    "    @property\n",
    "    def pvalue_permutation(self):\n",
    "        return self.__PermutationTest_result.pvalue\n",
    "    \n",
    "    # \n",
    "    # \n",
    "    @property\n",
    "    def permutation_count(self):\n",
    "        return self.__PermutationTest_result.permutation_count\n",
    "\n",
    "    \n",
    "    @property\n",
    "    def permutations(self):\n",
    "        return self.__PermutationTest_result.permutations\n",
    "\n",
    "    \n",
    "    @property\n",
    "    def permutations_var(self):\n",
    "        return self.__PermutationTest_result.permutations_var\n",
    "\n",
    "\n",
    "    @property\n",
    "    def proportional_difference(self):\n",
    "        from numpy import nan as npnan\n",
    "        try:\n",
    "            return self.__proportional_difference\n",
    "        except AttributeError:\n",
    "            return npnan\n",
    "\n",
    "\n",
    "\n",
    "    # Introduced in v0.2.8, removed in v0.3.0 for performance issues.\n",
    "#     @property\n",
    "#     def pvalue_lqrt_paired(self):\n",
    "#         from numpy import nan as npnan\n",
    "#         try:\n",
    "#             return self.__pvalue_paired_lqrt\n",
    "#         except AttributeError:\n",
    "#             return npnan\n",
    "\n",
    "\n",
    "\n",
    "#     @property\n",
    "#     def statistic_lqrt_paired(self):\n",
    "#         from numpy import nan as npnan\n",
    "#         try:\n",
    "#             return self.__statistic_paired_lqrt\n",
    "#         except AttributeError:\n",
    "#             return npnan\n",
    "            \n",
    "    \n",
    "#     @property\n",
    "#     def pvalue_lqrt_unpaired_equal_variance(self):\n",
    "#         from numpy import nan as npnan\n",
    "#         try:\n",
    "#             return self.__pvalue_lqrt_equal_var\n",
    "#         except AttributeError:\n",
    "#             return npnan\n",
    "\n",
    "\n",
    "\n",
    "#     @property\n",
    "#     def statistic_lqrt_unpaired_equal_variance(self):\n",
    "#         from numpy import nan as npnan\n",
    "#         try:\n",
    "#             return self.__statistic_lqrt_equal_var\n",
    "#         except AttributeError:\n",
    "#             return npnan\n",
    "            \n",
    "            \n",
    "#     @property\n",
    "#     def pvalue_lqrt_unpaired_unequal_variance(self):\n",
    "#         from numpy import nan as npnan\n",
    "#         try:\n",
    "#             return self.__pvalue_lqrt_unequal_var\n",
    "#         except AttributeError:\n",
    "#             return npnan\n",
    "\n",
    "\n",
    "\n",
    "#     @property\n",
    "#     def statistic_lqrt_unpaired_unequal_variance(self):\n",
    "#         from numpy import nan as npnan\n",
    "#         try:\n",
    "#             return self.__statistic_lqrt_unequal_var\n",
    "#         except AttributeError:\n",
    "#             return npnan\n",
    "    \n",
    "    \n",
    "    \n",
    "    # @property\n",
    "    # def power(self):\n",
    "    #     from numpy import nan as npnan\n",
    "    #     try:\n",
    "    #         return self.__power\n",
    "    #     except AttributeError:\n",
    "    #         return npnan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f95a7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class PermutationTest:\n",
    "    \"\"\"\n",
    "    A class to compute and report permutation tests.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    control : array-like\n",
    "    test : array-like\n",
    "        These should be numerical iterables.\n",
    "    effect_size : string.\n",
    "        Any one of the following are accepted inputs:\n",
    "        'mean_diff', 'median_diff', 'cohens_d', 'hedges_g', or 'cliffs_delta'\n",
    "    is_paired : string, default None\n",
    "    permutation_count : int, default 10000\n",
    "        The number of permutations (reshuffles) to perform.\n",
    "    random_seed : int, default 12345\n",
    "        `random_seed` is used to seed the random number generator during\n",
    "        bootstrap resampling. This ensures that the generated permutations\n",
    "        are replicable.\n",
    "\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A :py:class:`PermutationTest` object.\n",
    "    \n",
    "    difference : float\n",
    "        The effect size of the difference between the control and the test.\n",
    "    \n",
    "    effect_size : string\n",
    "        The type of effect size reported.\n",
    "        \n",
    "        \n",
    "    Notes\n",
    "    -----\n",
    "    The basic concept of permutation tests is the same as that behind bootstrapping.\n",
    "    In an \"exact\" permutation test, all possible resuffles of the control and test \n",
    "    labels are performed, and the proportion of effect sizes that equal or exceed \n",
    "    the observed effect size is computed. This is the probability, under the null \n",
    "    hypothesis of zero difference between test and control groups, of observing the\n",
    "    effect size: the p-value of the Student's t-test.\n",
    "    \n",
    "    Exact permutation tests are impractical: computing the effect sizes for all reshuffles quickly exceeds trivial computational loads. A control group and a test group both with 10 observations each would have a total of  :math:`20!` or :math:`2.43 \\\\times {10}^{18}` reshuffles.\n",
    "    Therefore, in practice, \"approximate\" permutation tests are performed, where a sufficient number of reshuffles are performed (5,000 or 10,000), from which the p-value is computed.\n",
    "    \n",
    "    More information can be found `here <https://en.wikipedia.org/wiki/Resampling_(statistics)#Permutation_tests>`_.\n",
    "    \n",
    "    \n",
    "    Example\n",
    "    -------\n",
    "    >>> import numpy as np\n",
    "    >>> from scipy.stats import norm\n",
    "    >>> import dabest\n",
    "    >>> control = norm.rvs(loc=0, size=30, random_state=12345)\n",
    "    >>> test = norm.rvs(loc=0.5, size=30, random_state=12345)\n",
    "    >>> perm_test = dabest.PermutationTest(control, test, \n",
    "    ...                                    effect_size=\"mean_diff\", \n",
    "    ...                                    paired=None)\n",
    "    >>> perm_test\n",
    "    5000 permutations were taken. The pvalue is 0.0758.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, control, test, \n",
    "                 effect_size, is_paired,\n",
    "                 permutation_count=5000, \n",
    "                 random_seed=12345,\n",
    "                 **kwargs):\n",
    "    \n",
    "        import numpy as np\n",
    "        from numpy.random import PCG64, RandomState\n",
    "#         from ._stats_tools.effsize import two_group_difference\n",
    "#         from ._stats_tools.confint_2group_diff import calculate_group_var\n",
    "\n",
    "        self.__permutation_count = permutation_count\n",
    "\n",
    "        # Run Sanity Check.\n",
    "        if is_paired and len(control) != len(test):\n",
    "            raise ValueError(\"The two arrays do not have the same length.\")\n",
    "\n",
    "        # Initialise random number generator.\n",
    "        # rng = np.random.default_rng(seed=random_seed)\n",
    "        rng = RandomState(PCG64(random_seed))\n",
    "\n",
    "        # Set required constants and variables\n",
    "        control = np.array(control)\n",
    "        test = np.array(test)\n",
    "\n",
    "        control_sample = control.copy()\n",
    "        test_sample    = test.copy()\n",
    "\n",
    "        BAG = np.array([*control, *test])\n",
    "        CONTROL_LEN = int(len(control))\n",
    "        EXTREME_COUNT = 0.\n",
    "        THRESHOLD = np.abs(two_group_difference(control, test, \n",
    "                                                is_paired, effect_size))\n",
    "        self.__permutations = []\n",
    "        self.__permutations_var = []\n",
    "\n",
    "        for i in range(int(permutation_count)):\n",
    "            \n",
    "            if is_paired:\n",
    "                # Select which control-test pairs to swap.\n",
    "                random_idx = rng.choice(CONTROL_LEN,\n",
    "                                rng.randint(0, CONTROL_LEN+1),\n",
    "                                replace=False)\n",
    "\n",
    "                # Perform swap.\n",
    "                for i in random_idx:\n",
    "                    _placeholder      = control_sample[i]\n",
    "                    control_sample[i] = test_sample[i]\n",
    "                    test_sample[i]    = _placeholder\n",
    "                \n",
    "            else:\n",
    "                # Shuffle the bag and assign to control and test groups.\n",
    "                # NB. rng.shuffle didn't produce replicable results...\n",
    "                shuffled = rng.permutation(BAG) \n",
    "                control_sample = shuffled[:CONTROL_LEN]\n",
    "                test_sample    = shuffled[CONTROL_LEN:]\n",
    "\n",
    "\n",
    "            es = two_group_difference(control_sample, test_sample, \n",
    "                                    False, effect_size)\n",
    "            \n",
    "            var = calculate_group_var(np.var(control_sample, ddof=1), \n",
    "                                      CONTROL_LEN, \n",
    "                                      np.var(test_sample, ddof=1), \n",
    "                                      len(test_sample))\n",
    "            self.__permutations.append(es)\n",
    "            self.__permutations_var.append(var)\n",
    "\n",
    "            if np.abs(es) > THRESHOLD:\n",
    "                EXTREME_COUNT += 1.\n",
    "\n",
    "        self.__permutations = np.array(self.__permutations)\n",
    "        self.__permutations_var = np.array(self.__permutations_var)\n",
    "\n",
    "        self.pvalue = EXTREME_COUNT / permutation_count\n",
    "\n",
    "\n",
    "    def __repr__(self):\n",
    "        return(\"{} permutations were taken. The p-value is {}.\".format(self.permutation_count, \n",
    "                                                                      self.pvalue))\n",
    "\n",
    "\n",
    "    @property\n",
    "    def permutation_count(self):\n",
    "        \"\"\"\n",
    "        The number of permuations taken.\n",
    "        \"\"\"\n",
    "        return self.__permutation_count\n",
    "\n",
    "\n",
    "    @property\n",
    "    def permutations(self):\n",
    "        \"\"\"\n",
    "        The effect sizes of all the permutations in a list.\n",
    "        \"\"\"\n",
    "        return self.__permutations\n",
    "\n",
    "    \n",
    "    @property\n",
    "    def permutations_var(self):\n",
    "        \"\"\"\n",
    "        The experiment group variance of all the permutations in a list.\n",
    "        \"\"\"\n",
    "        return self.__permutations_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91aa405f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
