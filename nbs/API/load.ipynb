{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data\n",
    "\n",
    "> Loading the data and the relevant groups \n",
    "\n",
    "- order: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from __future__ import annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "from nbdev.showdoc import *\n",
    "import nbdev\n",
    "nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "__version__ = \"0.3.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Dabest(object):\n",
    "\n",
    "    \"\"\"\n",
    "    Class for estimation statistics and plots.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data, idx, x, y, paired, id_col, ci, \n",
    "                resamples, random_seed, proportional, delta2, \n",
    "                experiment, experiment_label, x1_level, mini_meta):\n",
    "\n",
    "        \"\"\"\n",
    "        Parses and stores pandas DataFrames in preparation for estimation\n",
    "        statistics. You should not be calling this class directly; instead,\n",
    "        use `dabest.load()` to parse your DataFrame prior to analysis.\n",
    "        \"\"\"\n",
    "\n",
    "        # Import standard data science libraries.\n",
    "        import numpy as np\n",
    "        import pandas as pd\n",
    "        import seaborn as sns\n",
    "\n",
    "        self.__delta2       = delta2\n",
    "        self.__experiment   = experiment\n",
    "        self.__ci           = ci\n",
    "        self.__data         = data\n",
    "        self.__id_col       = id_col\n",
    "        self.__is_paired    = paired\n",
    "        self.__resamples    = resamples\n",
    "        self.__random_seed  = random_seed\n",
    "        self.__proportional = proportional\n",
    "        self.__mini_meta    = mini_meta \n",
    "\n",
    "        # Make a copy of the data, so we don't make alterations to it.\n",
    "        data_in = data.copy()\n",
    "        # data_in.reset_index(inplace=True)\n",
    "        # data_in_index_name = data_in.index.name\n",
    "\n",
    "\n",
    "        # Check if it is a valid mini_meta case\n",
    "        if mini_meta is True:\n",
    "            if proportional is True:\n",
    "                err0 = '`proportional` and `mini_meta` cannot be True at the same time.'\n",
    "                raise ValueError(err0)\n",
    "            elif delta2 is True:\n",
    "                err0 = '`delta` and `mini_meta` cannot be True at the same time.'\n",
    "                raise ValueError(err0)\n",
    "            \n",
    "            if all([isinstance(i, str) for i in idx]):\n",
    "                if len(pd.unique([t for t in idx]).tolist())!=2:\n",
    "                    err0 = '`mini_meta` is True, but `idx` ({})'.format(idx) \n",
    "                    err1 = 'does not contain exactly 2 columns.'\n",
    "                    raise ValueError(err0 + err1)\n",
    "            elif all([isinstance(i, (tuple, list)) for i in idx]):\n",
    "                all_idx_lengths = [len(t) for t in idx]\n",
    "                if (np.array(all_idx_lengths) != 2).any():\n",
    "                    err1 = \"`mini_meta` is True, but some idx \"\n",
    "                    err2 = \"in {} does not consist only of two groups.\".format(idx)\n",
    "                    raise ValueError(err1 + err2)\n",
    "            \n",
    "\n",
    "\n",
    "        # Check if this is a 2x2 ANOVA case and x & y are valid columns\n",
    "        # Create experiment_label and x1_level\n",
    "        if delta2 is True:\n",
    "            if proportional is True:\n",
    "                err0 = '`proportional` and `delta` cannot be True at the same time.'\n",
    "                raise ValueError(err0)\n",
    "            # idx should not be specified\n",
    "            if idx:\n",
    "                err0 = '`idx` should not be specified when `delta2` is True.'.format(len(x))\n",
    "                raise ValueError(err0)\n",
    "\n",
    "            # Check if x is valid\n",
    "            if len(x) != 2:\n",
    "                err0 = '`delta2` is True but the number of variables indicated by `x` is {}.'.format(len(x))\n",
    "                raise ValueError(err0)\n",
    "            else:\n",
    "                for i in x:\n",
    "                    if i not in data_in.columns:\n",
    "                        err = '{0} is not a column in `data`. Please check.'.format(i)\n",
    "                        raise IndexError(err)\n",
    "\n",
    "            # Check if y is valid\n",
    "            if not y:\n",
    "                err0 = '`delta2` is True but `y` is not indicated.'\n",
    "                raise ValueError(err0)\n",
    "            elif y not in data_in.columns:\n",
    "                err = '{0} is not a column in `data`. Please check.'.format(y)\n",
    "                raise IndexError(err)\n",
    "\n",
    "            # Check if experiment is valid\n",
    "            if experiment not in data_in.columns:\n",
    "                err = '{0} is not a column in `data`. Please check.'.format(experiment)\n",
    "                raise IndexError(err)\n",
    "\n",
    "            # Check if experiment_label is valid and create experiment when needed\n",
    "            if experiment_label:\n",
    "                if len(experiment_label) != 2:\n",
    "                    err0 = '`experiment_label` does not have a length of 2.'\n",
    "                    raise ValueError(err0)\n",
    "                else: \n",
    "                    for i in experiment_label:\n",
    "                        if i not in data_in[experiment].unique():\n",
    "                            err = '{0} is not an element in the column `{1}` of `data`. Please check.'.format(i, experiment)\n",
    "                            raise IndexError(err)\n",
    "            else:\n",
    "                experiment_label = data_in[experiment].unique()\n",
    "\n",
    "            # Check if x1_level is valid\n",
    "            if x1_level:\n",
    "                if len(x1_level) != 2:\n",
    "                    err0 = '`x1_level` does not have a length of 2.'\n",
    "                    raise ValueError(err0)\n",
    "                else: \n",
    "                    for i in x1_level:\n",
    "                        if i not in data_in[x[0]].unique():\n",
    "                            err = '{0} is not an element in the column `{1}` of `data`. Please check.'.format(i, experiment)\n",
    "                            raise IndexError(err)\n",
    "\n",
    "            else:\n",
    "                x1_level = data_in[x[0]].unique()    \n",
    "        self.__experiment_label = experiment_label\n",
    "        self.__x1_level         = x1_level\n",
    "\n",
    "\n",
    "        # Check if idx is specified\n",
    "        if delta2 is False and not idx:\n",
    "            err = '`idx` is not a column in `data`. Please check.'\n",
    "            raise IndexError(err)\n",
    "\n",
    "\n",
    "        # create new x & idx and record the second variable if this is a valid 2x2 ANOVA case\n",
    "        if delta2 is True:\n",
    "            # add a new column which is a combination of experiment and the first variable\n",
    "            new_col_name = experiment+x[0]\n",
    "            while new_col_name in data_in.columns:\n",
    "                new_col_name += \"_\"\n",
    "            data_in[new_col_name] = data_in[x[0]].astype(str) + \" \" + data_in[experiment].astype(str)\n",
    "\n",
    "            #create idx            \n",
    "            idx = []\n",
    "            for i in list(map(lambda x: str(x), experiment_label)):\n",
    "                temp = []\n",
    "                for j in list(map(lambda x: str(x), x1_level)):\n",
    "                    temp.append(j + \" \" + i)\n",
    "                idx.append(temp)         \n",
    "            self.__idx = idx\n",
    "            self.__x1  = x[0]\n",
    "            self.__x2  = x[1]\n",
    "            # record the second variable and create idx\n",
    "            x = new_col_name\n",
    "        else:\n",
    "            self.__idx = idx\n",
    "            self.__x1  = None\n",
    "            self.__x2  = None\n",
    "\n",
    "        # Determine the kind of estimation plot we need to produce.\n",
    "        if all([isinstance(i, str) for i in idx]):\n",
    "            # flatten out idx.\n",
    "            all_plot_groups = pd.unique([t for t in idx]).tolist()\n",
    "            if len(idx) > len(all_plot_groups):\n",
    "                err0 = '`idx` contains duplicated groups. Please remove any duplicates and try again.'\n",
    "                raise ValueError(err0)\n",
    "                \n",
    "            # We need to re-wrap this idx inside another tuple so as to\n",
    "            # easily loop thru each pairwise group later on.\n",
    "            self.__idx = (idx,)\n",
    "\n",
    "        elif all([isinstance(i, (tuple, list)) for i in idx]):\n",
    "            all_plot_groups = pd.unique([tt for t in idx for tt in t]).tolist()\n",
    "            \n",
    "            actual_groups_given = sum([len(i) for i in idx])\n",
    "            \n",
    "            if actual_groups_given > len(all_plot_groups):\n",
    "                err0 = 'Groups are repeated across tuples,'\n",
    "                err1 = ' or a tuple has repeated groups in it.'\n",
    "                err2 = ' Please remove any duplicates and try again.'\n",
    "                raise ValueError(err0 + err1 + err2)\n",
    "\n",
    "        else: # mix of string and tuple?\n",
    "            err = 'There seems to be a problem with the idx you'\n",
    "            'entered--{}.'.format(idx)\n",
    "            raise ValueError(err)\n",
    "\n",
    "        # Having parsed the idx, check if it is a kosher paired plot,\n",
    "        # if so stated.\n",
    "        #if paired is True:\n",
    "        #    all_idx_lengths = [len(t) for t in self.__idx]\n",
    "        #    if (np.array(all_idx_lengths) != 2).any():\n",
    "        #        err1 = \"`is_paired` is True, but some idx \"\n",
    "        #        err2 = \"in {} does not consist only of two groups.\".format(idx)\n",
    "        #        raise ValueError(err1 + err2)\n",
    "\n",
    "        # Check if there is a typo on paired\n",
    "        if paired:\n",
    "            if paired not in (\"baseline\", \"sequential\"):\n",
    "                err = '{} assigned for `paired` is not valid.'.format(paired)\n",
    "                raise ValueError(err)\n",
    "\n",
    "\n",
    "        # Determine the type of data: wide or long.\n",
    "        if x is None and y is not None:\n",
    "            err = 'You have only specified `y`. Please also specify `x`.'\n",
    "            raise ValueError(err)\n",
    "\n",
    "        elif y is None and x is not None:\n",
    "            err = 'You have only specified `x`. Please also specify `y`.'\n",
    "            raise ValueError(err)\n",
    "\n",
    "        # Identify the type of data that was passed in.\n",
    "        elif x is not None and y is not None:\n",
    "            # Assume we have a long dataset.\n",
    "            # check both x and y are column names in data.\n",
    "            if x not in data_in.columns:\n",
    "                err = '{0} is not a column in `data`. Please check.'.format(x)\n",
    "                raise IndexError(err)\n",
    "            if y not in data_in.columns:\n",
    "                err = '{0} is not a column in `data`. Please check.'.format(y)\n",
    "                raise IndexError(err)\n",
    "\n",
    "            # check y is numeric.\n",
    "            if not np.issubdtype(data_in[y].dtype, np.number):\n",
    "                err = '{0} is a column in `data`, but it is not numeric.'.format(y)\n",
    "                raise ValueError(err)\n",
    "\n",
    "            # check all the idx can be found in data_in[x]\n",
    "            for g in all_plot_groups:\n",
    "                if g not in data_in[x].unique():\n",
    "                    err0 = '\"{0}\" is not a group in the column `{1}`.'.format(g, x)\n",
    "                    err1 = \" Please check `idx` and try again.\"\n",
    "                    raise IndexError(err0 + err1)\n",
    "\n",
    "            # Select only rows where the value in the `x` column \n",
    "            # is found in `idx`.\n",
    "            plot_data = data_in[data_in.loc[:, x].isin(all_plot_groups)].copy()\n",
    "            \n",
    "            # plot_data.drop(\"index\", inplace=True, axis=1)\n",
    "\n",
    "            # Assign attributes\n",
    "            self.__x = x\n",
    "            self.__y = y\n",
    "            self.__xvar = x\n",
    "            self.__yvar = y\n",
    "\n",
    "        elif x is None and y is None:\n",
    "            # Assume we have a wide dataset.\n",
    "            # Assign attributes appropriately.\n",
    "            self.__x = None\n",
    "            self.__y = None\n",
    "            self.__xvar = \"group\"\n",
    "            self.__yvar = \"value\"\n",
    "\n",
    "            # First, check we have all columns in the dataset.\n",
    "            for g in all_plot_groups:\n",
    "                if g not in data_in.columns:\n",
    "                    err0 = '\"{0}\" is not a column in `data`.'.format(g)\n",
    "                    err1 = \" Please check `idx` and try again.\"\n",
    "                    raise IndexError(err0 + err1)\n",
    "                    \n",
    "            set_all_columns     = set(data_in.columns.tolist())\n",
    "            set_all_plot_groups = set(all_plot_groups)\n",
    "            id_vars = set_all_columns.difference(set_all_plot_groups)\n",
    "\n",
    "            plot_data = pd.melt(data_in,\n",
    "                                id_vars=id_vars,\n",
    "                                value_vars=all_plot_groups,\n",
    "                                value_name=self.__yvar,\n",
    "                                var_name=self.__xvar)\n",
    "                                \n",
    "        # Added in v0.2.7.\n",
    "        # remove any NA rows.\n",
    "        plot_data.dropna(axis=0, how='any', subset=[self.__yvar], inplace=True)\n",
    "\n",
    "        \n",
    "        # Lines 131 to 140 added in v0.2.3.\n",
    "        # Fixes a bug that jammed up when the xvar column was already \n",
    "        # a pandas Categorical. Now we check for this and act appropriately.\n",
    "        if isinstance(plot_data[self.__xvar].dtype, \n",
    "                      pd.CategoricalDtype) is True:\n",
    "            plot_data[self.__xvar].cat.remove_unused_categories(inplace=True)\n",
    "            plot_data[self.__xvar].cat.reorder_categories(all_plot_groups, \n",
    "                                                          ordered=True, \n",
    "                                                          inplace=True)\n",
    "        else:\n",
    "            plot_data.loc[:, self.__xvar] = pd.Categorical(plot_data[self.__xvar],\n",
    "                                               categories=all_plot_groups,\n",
    "                                               ordered=True)\n",
    "        \n",
    "        # # The line below was added in v0.2.4, removed in v0.2.5.\n",
    "        # plot_data.dropna(inplace=True)\n",
    "        \n",
    "        self.__plot_data = plot_data\n",
    "        \n",
    "        self.__all_plot_groups = all_plot_groups\n",
    "\n",
    "\n",
    "        # Sanity check that all idxs are paired, if so desired.\n",
    "        #if paired is True:\n",
    "        #    if id_col is None:\n",
    "        #        err = \"`id_col` must be specified if `is_paired` is set to True.\"\n",
    "        #        raise IndexError(err)\n",
    "        #    elif id_col not in plot_data.columns:\n",
    "        #        err = \"{} is not a column in `data`. \".format(id_col)\n",
    "        #        raise IndexError(err)\n",
    "\n",
    "        # Check if `id_col` is valid\n",
    "        if paired:\n",
    "            if id_col is None:\n",
    "                err = \"`id_col` must be specified if `paired` is assigned with a not NoneType value.\"\n",
    "                raise IndexError(err)\n",
    "            elif id_col not in plot_data.columns:\n",
    "                err = \"{} is not a column in `data`. \".format(id_col)\n",
    "                raise IndexError(err)\n",
    "\n",
    "        EffectSizeDataFrame_kwargs = dict(ci=ci, is_paired=paired,\n",
    "                                           random_seed=random_seed,\n",
    "                                           resamples=resamples,\n",
    "                                           proportional=proportional, \n",
    "                                           delta2=delta2, \n",
    "                                           experiment_label=self.__experiment_label,\n",
    "                                           x1_level=self.__x1_level,\n",
    "                                           x2=self.__x2,\n",
    "                                           mini_meta = mini_meta)\n",
    "\n",
    "        self.__mean_diff    = EffectSizeDataFrame(self, \"mean_diff\",\n",
    "                                                **EffectSizeDataFrame_kwargs)\n",
    "\n",
    "        self.__median_diff  = EffectSizeDataFrame(self, \"median_diff\",\n",
    "                                               **EffectSizeDataFrame_kwargs)\n",
    "\n",
    "        self.__cohens_d     = EffectSizeDataFrame(self, \"cohens_d\",\n",
    "                                                **EffectSizeDataFrame_kwargs)\n",
    "\n",
    "        self.__cohens_h     = EffectSizeDataFrame(self, \"cohens_h\",\n",
    "                                                **EffectSizeDataFrame_kwargs)                                       \n",
    "\n",
    "        self.__hedges_g     = EffectSizeDataFrame(self, \"hedges_g\",\n",
    "                                                **EffectSizeDataFrame_kwargs)\n",
    "\n",
    "        if not paired:\n",
    "            self.__cliffs_delta = EffectSizeDataFrame(self, \"cliffs_delta\",\n",
    "                                                    **EffectSizeDataFrame_kwargs)\n",
    "        else:\n",
    "            self.__cliffs_delta = \"The data is paired; Cliff's delta is therefore undefined.\"\n",
    "\n",
    "\n",
    "    def __repr__(self):\n",
    "        # from .__init__ import __version__\n",
    "        import datetime as dt\n",
    "        import numpy as np\n",
    "\n",
    "        # from .misc_tools import print_greeting\n",
    "\n",
    "        # Removed due to the deprecation of is_paired\n",
    "        #if self.__is_paired:\n",
    "        #    es = \"Paired e\"\n",
    "        #else:\n",
    "        #    es = \"E\"\n",
    "\n",
    "        greeting_header = print_greeting()\n",
    "\n",
    "        RM_STATUS = {'baseline'  : 'for repeated measures against baseline \\n', \n",
    "                     'sequential': 'for the sequential design of repeated-measures experiment \\n',\n",
    "                     'None'      : ''\n",
    "                    }\n",
    "\n",
    "        PAIRED_STATUS = {'baseline'   : 'Paired e', \n",
    "                         'sequential' : 'Paired e',\n",
    "                         'None'       : 'E'\n",
    "        }\n",
    "\n",
    "        first_line = {\"rm_status\"    : RM_STATUS[str(self.__is_paired)],\n",
    "                      \"paired_status\": PAIRED_STATUS[str(self.__is_paired)]}\n",
    "\n",
    "        s1 = \"{paired_status}ffect size(s) {rm_status}\".format(**first_line)\n",
    "        s2 = \"with {}% confidence intervals will be computed for:\".format(self.__ci)\n",
    "        desc_line = s1 + s2\n",
    "\n",
    "        out = [greeting_header + \"\\n\\n\" + desc_line]\n",
    "\n",
    "        comparisons = []\n",
    "\n",
    "        if self.__is_paired == 'sequential':\n",
    "            for j, current_tuple in enumerate(self.__idx):\n",
    "                for ix, test_name in enumerate(current_tuple[1:]):\n",
    "                    control_name = current_tuple[ix]\n",
    "                    comparisons.append(\"{} minus {}\".format(test_name, control_name))\n",
    "        else:\n",
    "            for j, current_tuple in enumerate(self.__idx):\n",
    "                control_name = current_tuple[0]\n",
    "\n",
    "                for ix, test_name in enumerate(current_tuple[1:]):\n",
    "                    comparisons.append(\"{} minus {}\".format(test_name, control_name))\n",
    "\n",
    "        if self.__delta2 is True:\n",
    "            comparisons.append(\"{} minus {} (only for mean difference)\".format(self.__experiment_label[1], self.__experiment_label[0]))\n",
    "        \n",
    "        if self.__mini_meta is True:\n",
    "            comparisons.append(\"weighted delta (only for mean difference)\")\n",
    "\n",
    "        for j, g in enumerate(comparisons):\n",
    "            out.append(\"{}. {}\".format(j+1, g))\n",
    "\n",
    "        resamples_line1 = \"\\n{} resamples \".format(self.__resamples)\n",
    "        resamples_line2 = \"will be used to generate the effect size bootstraps.\"\n",
    "        out.append(resamples_line1 + resamples_line2)\n",
    "\n",
    "        return \"\\n\".join(out)\n",
    "\n",
    "\n",
    "    # def __variable_name(self):\n",
    "    #     return [k for k,v in locals().items() if v is self]\n",
    "    #\n",
    "    # @property\n",
    "    # def variable_name(self):\n",
    "    #     return self.__variable_name()\n",
    "    \n",
    "    @property\n",
    "    def mean_diff(self):\n",
    "        \"\"\"\n",
    "        Returns an :py:class:`EffectSizeDataFrame` for the mean difference, its confidence interval, and relevant statistics, for all comparisons as indicated via the `idx` and `paired` argument in `dabest.load()`.\n",
    "        \n",
    "        Example\n",
    "        -------\n",
    "        >>> from scipy.stats import norm\n",
    "        >>> import pandas as pd\n",
    "        >>> import dabest\n",
    "        >>> control = norm.rvs(loc=0, size=30, random_state=12345)\n",
    "        >>> test    = norm.rvs(loc=0.5, size=30, random_state=12345)\n",
    "        >>> my_df   = pd.DataFrame({\"control\": control,\n",
    "                                    \"test\": test})\n",
    "        >>> my_dabest_object = dabest.load(my_df, idx=(\"control\", \"test\"))\n",
    "        >>> my_dabest_object.mean_diff\n",
    "        \n",
    "        Notes\n",
    "        -----\n",
    "        This is simply the mean of the control group subtracted from\n",
    "        the mean of the test group.\n",
    "        \n",
    "        .. math::\n",
    "            \\\\text{Mean difference} = \\\\overline{x}_{Test} - \\\\overline{x}_{Control}\n",
    "            \n",
    "        where :math:`\\\\overline{x}` is the mean for the group :math:`x`.\n",
    "        \"\"\"\n",
    "        return self.__mean_diff\n",
    "        \n",
    "        \n",
    "    @property    \n",
    "    def median_diff(self):\n",
    "        \"\"\"\n",
    "        Returns an :py:class:`EffectSizeDataFrame` for the median difference, its confidence interval, and relevant statistics, for all comparisons  as indicated via the `idx` and `paired` argument in `dabest.load()`.\n",
    "        \n",
    "        Example\n",
    "        -------\n",
    "        >>> from scipy.stats import norm\n",
    "        >>> import pandas as pd\n",
    "        >>> import dabest\n",
    "        >>> control = norm.rvs(loc=0, size=30, random_state=12345)\n",
    "        >>> test    = norm.rvs(loc=0.5, size=30, random_state=12345)\n",
    "        >>> my_df   = pd.DataFrame({\"control\": control,\n",
    "                                    \"test\": test})\n",
    "        >>> my_dabest_object = dabest.load(my_df, idx=(\"control\", \"test\"))\n",
    "        >>> my_dabest_object.median_diff\n",
    "        \n",
    "        Notes\n",
    "        -----\n",
    "        This is the median difference between the control group and the test group.\n",
    "        \n",
    "        If the comparison(s) are unpaired, median_diff is computed with the following equation:\n",
    "\n",
    "        .. math::\n",
    "            \\\\text{Median difference} = \\\\widetilde{x}_{Test} - \\\\widetilde{x}_{Control}\n",
    "            \n",
    "        where :math:`\\\\widetilde{x}` is the median for the group :math:`x`.\n",
    "\n",
    "        If the comparison(s) are paired, median_diff is computed with the following equation:\n",
    "\n",
    "        .. math::\n",
    "            \\\\text{Median difference} = \\\\widetilde{x}_{Test - Control}\n",
    "\n",
    "        \"\"\"\n",
    "        return self.__median_diff\n",
    "        \n",
    "        \n",
    "    @property\n",
    "    def cohens_d(self):\n",
    "        \"\"\"\n",
    "        Returns an :py:class:`EffectSizeDataFrame` for the standardized mean difference Cohen's `d`, its confidence interval, and relevant statistics, for all comparisons as indicated via the `idx` and `paired` argument in `dabest.load()`.\n",
    "        \n",
    "        Example\n",
    "        -------\n",
    "        >>> from scipy.stats import norm\n",
    "        >>> import pandas as pd\n",
    "        >>> import dabest\n",
    "        >>> control = norm.rvs(loc=0, size=30, random_state=12345)\n",
    "        >>> test    = norm.rvs(loc=0.5, size=30, random_state=12345)\n",
    "        >>> my_df   = pd.DataFrame({\"control\": control,\n",
    "                                    \"test\": test})\n",
    "        >>> my_dabest_object = dabest.load(my_df, idx=(\"control\", \"test\"))\n",
    "        >>> my_dabest_object.cohens_d\n",
    "        \n",
    "        Notes\n",
    "        -----\n",
    "        Cohen's `d` is simply the mean of the control group subtracted from\n",
    "        the mean of the test group.\n",
    "        \n",
    "        If `paired` is None, then the comparison(s) are unpaired; \n",
    "        otherwise the comparison(s) are paired.\n",
    "\n",
    "        If the comparison(s) are unpaired, Cohen's `d` is computed with the following equation:\n",
    "        \n",
    "        .. math::\n",
    "            \n",
    "            d = \\\\frac{\\\\overline{x}_{Test} - \\\\overline{x}_{Control}} {\\\\text{pooled standard deviation}}\n",
    "                \n",
    "        \n",
    "        For paired comparisons, Cohen's d is given by\n",
    "        \n",
    "        .. math::\n",
    "            d = \\\\frac{\\\\overline{x}_{Test} - \\\\overline{x}_{Control}} {\\\\text{average standard deviation}}\n",
    "            \n",
    "        where :math:`\\\\overline{x}` is the mean of the respective group of observations, :math:`{Var}_{x}` denotes the variance of that group,\n",
    "        \n",
    "        .. math::\n",
    "        \n",
    "            \\\\text{pooled standard deviation} = \\\\sqrt{ \\\\frac{(n_{control} - 1) * {Var}_{control} + (n_{test} - 1) * {Var}_{test} } {n_{control} + n_{test} - 2} }\n",
    "        \n",
    "        and\n",
    "        \n",
    "        .. math::\n",
    "        \n",
    "            \\\\text{average standard deviation} = \\\\sqrt{ \\\\frac{{Var}_{control} + {Var}_{test}} {2}}\n",
    "            \n",
    "        The sample variance (and standard deviation) uses N-1 degrees of freedoms.\n",
    "        This is an application of `Bessel's correction <https://en.wikipedia.org/wiki/Bessel%27s_correction>`_, and yields the unbiased\n",
    "        sample variance.\n",
    "        \n",
    "        References:\n",
    "            https://en.wikipedia.org/wiki/Effect_size#Cohen's_d\n",
    "            https://en.wikipedia.org/wiki/Bessel%27s_correction\n",
    "            https://en.wikipedia.org/wiki/Standard_deviation#Corrected_sample_standard_deviation\n",
    "        \"\"\"\n",
    "        return self.__cohens_d\n",
    "    \n",
    "    \n",
    "    @property\n",
    "    def cohens_h(self):\n",
    "        \"\"\"\n",
    "        Returns an :py:class:`EffectSizeDataFrame` for the standardized mean difference Cohen's `h`, its confidence interval, and relevant statistics, for all comparisons as indicated via the `idx` and `directional` argument in `dabest.load()`.\n",
    "\n",
    "        Example\n",
    "        -------\n",
    "        >>> from scipy.stats import randint\n",
    "        >>> import pandas as pd\n",
    "        >>> import dabest\n",
    "        >>> control = randint.rvs(0, 2, size=30, random_state=12345)\n",
    "        >>> test    = randint.rvs(0, 2, size=30, random_state=12345)\n",
    "        >>> my_df   = pd.DataFrame({\"control\": control,\n",
    "                                    \"test\": test})\n",
    "        >>> my_dabest_object = dabest.load(my_df, idx=(\"control\", \"test\")\n",
    "        >>> my_dabest_object.cohens_h\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        Cohen's 'h' uses the information of proportion in the control and test groups to calculate the distance between two proportions.\n",
    "        It can be used to describe the difference between two proportions as \"small\", \"medium\", or \"large\".\n",
    "        It can be used to determine if the difference between two proportions is \"meaningful\".\n",
    "\n",
    "        A directional Cohen's 'h' is computed with the following equation:\n",
    "\n",
    "        .. math::\n",
    "            h = 2 * \\\\arcsin{\\\\sqrt{proportion_{Test}}} - 2 * \\\\arcsin{\\\\sqrt{proportion_{Control}}}\n",
    "\n",
    "        For a non-directional Cohen's 'h', the equation is:\n",
    "        .. math::\n",
    "            h = \\\\abs{2 * \\\\arcsin{\\\\sqrt{proportion_{Test}}}} - \\\\abs{2 * \\\\arcsin{\\\\sqrt{proportion_{Control}}}}\n",
    "        \n",
    "        References:\n",
    "            https://en.wikipedia.org/wiki/Cohen%27s_h\n",
    "        \"\"\"\n",
    "        return self.__cohens_h\n",
    "\n",
    "\n",
    "    @property  \n",
    "    def hedges_g(self):\n",
    "        \"\"\"\n",
    "        Returns an :py:class:`EffectSizeDataFrame` for the standardized mean difference Hedges' `g`, its confidence interval, and relevant statistics, for all comparisons as indicated via the `idx` and `paired` argument in `dabest.load()`.\n",
    "        \n",
    "        \n",
    "        Example\n",
    "        -------\n",
    "        >>> from scipy.stats import norm\n",
    "        >>> import pandas as pd\n",
    "        >>> import dabest\n",
    "        >>> control = norm.rvs(loc=0, size=30, random_state=12345)\n",
    "        >>> test    = norm.rvs(loc=0.5, size=30, random_state=12345)\n",
    "        >>> my_df   = pd.DataFrame({\"control\": control,\n",
    "                                    \"test\": test})\n",
    "        >>> my_dabest_object = dabest.load(my_df, idx=(\"control\", \"test\"))\n",
    "        >>> my_dabest_object.hedges_g\n",
    "        \n",
    "        Notes\n",
    "        -----\n",
    "        \n",
    "        Hedges' `g` is :py:attr:`cohens_d` corrected for bias via multiplication with the following correction factor:\n",
    "        \n",
    "        .. math::\n",
    "            \\\\frac{ \\\\Gamma( \\\\frac{a} {2} )} {\\\\sqrt{ \\\\frac{a} {2} } \\\\times \\\\Gamma( \\\\frac{a - 1} {2} )}\n",
    "            \n",
    "        where\n",
    "        \n",
    "        .. math::\n",
    "            a = {n}_{control} + {n}_{test} - 2\n",
    "            \n",
    "        and :math:`\\\\Gamma(x)` is the `Gamma function <https://en.wikipedia.org/wiki/Gamma_function>`_.\n",
    "            \n",
    "        \n",
    "        \n",
    "        References:\n",
    "            https://en.wikipedia.org/wiki/Effect_size#Hedges'_g\n",
    "            https://journals.sagepub.com/doi/10.3102/10769986006002107\n",
    "        \"\"\"\n",
    "        return self.__hedges_g\n",
    "        \n",
    "        \n",
    "    @property    \n",
    "    def cliffs_delta(self):\n",
    "        \"\"\"\n",
    "        Returns an :py:class:`EffectSizeDataFrame` for Cliff's delta, its confidence interval, and relevant statistics, for all comparisons as indicated via the `idx` and `paired` argument in `dabest.load()`.\n",
    "        \n",
    "        \n",
    "        Example\n",
    "        -------\n",
    "        >>> from scipy.stats import norm\n",
    "        >>> import pandas as pd\n",
    "        >>> import dabest\n",
    "        >>> control = norm.rvs(loc=0, size=30, random_state=12345)\n",
    "        >>> test    = norm.rvs(loc=0.5, size=30, random_state=12345)\n",
    "        >>> my_df   = pd.DataFrame({\"control\": control,\n",
    "                                    \"test\": test})\n",
    "        >>> my_dabest_object = dabest.load(my_df, idx=(\"control\", \"test\"))\n",
    "        >>> my_dabest_object.cliffs_delta\n",
    "        \n",
    "        \n",
    "        Notes\n",
    "        -----\n",
    "        \n",
    "        Cliff's delta is a measure of ordinal dominance, ie. how often the values from the test sample are larger than values from the control sample.\n",
    "        \n",
    "        .. math::\n",
    "            \\\\text{Cliff's delta} = \\\\frac{\\\\#({x}_{test} > {x}_{control}) - \\\\#({x}_{test} < {x}_{control})} {{n}_{Test} \\\\times {n}_{Control}}\n",
    "            \n",
    "            \n",
    "        where :math:`\\\\#` denotes the number of times a value from the test sample exceeds (or is lesser than) values in the control sample. \n",
    "         \n",
    "        Cliff's delta ranges from -1 to 1; it can also be thought of as a measure of the degree of overlap between the two samples. An attractive aspect of this effect size is that it does not make an assumptions about the underlying distributions that the samples were drawn from. \n",
    "        \n",
    "        References:\n",
    "            https://en.wikipedia.org/wiki/Effect_size#Effect_size_for_ordinal_data\n",
    "            https://psycnet.apa.org/record/1994-08169-001\n",
    "        \"\"\"\n",
    "        return self.__cliffs_delta\n",
    "\n",
    "\n",
    "    @property\n",
    "    def data(self):\n",
    "        \"\"\"\n",
    "        Returns the pandas DataFrame that was passed to `dabest.load()`.\n",
    "        \"\"\"\n",
    "        return self.__data\n",
    "\n",
    "\n",
    "    @property\n",
    "    def idx(self):\n",
    "        \"\"\"\n",
    "        Returns the order of categories that was passed to `dabest.load()`.\n",
    "        \"\"\"\n",
    "        return self.__idx\n",
    "    \n",
    "\n",
    "    @property\n",
    "    def x1(self):\n",
    "        return self.__x1\n",
    "\n",
    "\n",
    "    @property\n",
    "    def x1_level(self):\n",
    "        return self.__x1_level\n",
    "\n",
    "\n",
    "    @property\n",
    "    def x2(self):\n",
    "        return self.__x2\n",
    "\n",
    "\n",
    "    @property\n",
    "    def experiment(self):\n",
    "        return self.__experiment\n",
    "    \n",
    "\n",
    "    @property\n",
    "    def experiment_label(self):\n",
    "        return self.__experiment_label\n",
    "\n",
    "\n",
    "    @property\n",
    "    def delta2(self):\n",
    "        return self.__delta2\n",
    "\n",
    "\n",
    "    @property\n",
    "    def is_paired(self):\n",
    "        \"\"\"\n",
    "        Returns the type of repeated-measures experiment.\n",
    "        \"\"\"\n",
    "        return self.__is_paired\n",
    "\n",
    "\n",
    "    @property\n",
    "    def id_col(self):\n",
    "        \"\"\"\n",
    "        Returns the id column declared to `dabest.load()`.\n",
    "        \"\"\"\n",
    "        return self.__id_col\n",
    "\n",
    "\n",
    "    @property\n",
    "    def ci(self):\n",
    "        \"\"\"\n",
    "        The width of the desired confidence interval.\n",
    "        \"\"\"\n",
    "        return self.__ci\n",
    "\n",
    "\n",
    "    @property\n",
    "    def resamples(self):\n",
    "        \"\"\"\n",
    "        The number of resamples used to generate the bootstrap.\n",
    "        \"\"\"\n",
    "        return self.__resamples\n",
    "\n",
    "\n",
    "    @property\n",
    "    def random_seed(self):\n",
    "        \"\"\"\n",
    "        The number used to initialise the numpy random seed generator, ie.\n",
    "        `seed_value` from `numpy.random.seed(seed_value)` is returned.\n",
    "        \"\"\"\n",
    "        return self.__random_seed\n",
    "\n",
    "\n",
    "    @property\n",
    "    def x(self):\n",
    "        \"\"\"\n",
    "        Returns the x column that was passed to `dabest.load()`, if any.\n",
    "        \"\"\"\n",
    "        return self.__x\n",
    "\n",
    "\n",
    "    @property\n",
    "    def y(self):\n",
    "        \"\"\"\n",
    "        Returns the y column that was passed to `dabest.load()`, if any.\n",
    "        \"\"\"\n",
    "        return self.__y\n",
    "\n",
    "\n",
    "    @property\n",
    "    def _xvar(self):\n",
    "        \"\"\"\n",
    "        Returns the xvar in dabest.plot_data.\n",
    "        \"\"\"\n",
    "        return self.__xvar\n",
    "\n",
    "\n",
    "    @property\n",
    "    def _yvar(self):\n",
    "        \"\"\"\n",
    "        Returns the yvar in dabest.plot_data.\n",
    "        \"\"\"\n",
    "        return self.__yvar\n",
    "\n",
    "\n",
    "    @property\n",
    "    def _plot_data(self):\n",
    "        \"\"\"\n",
    "        Returns the pandas DataFrame used to produce the estimation stats/plots.\n",
    "        \"\"\"\n",
    "        return self.__plot_data\n",
    "\n",
    "    \n",
    "    @property\n",
    "    def proportional(self):\n",
    "        \"\"\"\n",
    "        Returns the proportional parameter class.\n",
    "        \"\"\"\n",
    "        return self.__proportional\n",
    "\n",
    "    \n",
    "    @property\n",
    "    def mini_meta(self):\n",
    "        \"\"\"\n",
    "        Returns the mini_meta boolean parameter.\n",
    "        \"\"\"\n",
    "        return self.__mini_meta\n",
    "\n",
    "\n",
    "    @property\n",
    "    def _all_plot_groups(self):\n",
    "        \"\"\"\n",
    "        Returns the all plot groups, as indicated via the `idx` keyword.\n",
    "        \"\"\"\n",
    "        return self.__all_plot_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class EffectSizeDataFrame(object):\n",
    "    \"\"\"A class that generates and stores the results of bootstrapped effect\n",
    "    sizes for several comparisons.\"\"\"\n",
    "\n",
    "    def __init__(self, dabest, effect_size,\n",
    "                 is_paired, ci=95, proportional=False,\n",
    "                 resamples=5000, \n",
    "                 permutation_count=5000,\n",
    "                 random_seed=12345, \n",
    "                 x1_level=None, x2=None, \n",
    "                 delta2=False, experiment_label=None,\n",
    "                 mini_meta=False):\n",
    "        \"\"\"\n",
    "        Parses the data from a Dabest object, enabling plotting and printing\n",
    "        capability for the effect size of interest.\n",
    "        \"\"\"\n",
    "\n",
    "        self.__dabest_obj        = dabest\n",
    "        self.__effect_size       = effect_size\n",
    "        self.__is_paired         = is_paired\n",
    "        self.__ci                = ci\n",
    "        self.__resamples         = resamples\n",
    "        self.__permutation_count = permutation_count\n",
    "        self.__random_seed       = random_seed\n",
    "        self.__proportional      = proportional\n",
    "        self.__x1_level          = x1_level\n",
    "        self.__experiment_label  = experiment_label \n",
    "        self.__x2                = x2\n",
    "        self.__delta2            = delta2 \n",
    "        self.__mini_meta         = mini_meta\n",
    "\n",
    "\n",
    "    def __pre_calc(self):\n",
    "        import pandas as pd\n",
    "        # from .misc_tools import print_greeting, get_varname\n",
    "\n",
    "        idx  = self.__dabest_obj.idx\n",
    "        dat  = self.__dabest_obj._plot_data\n",
    "        xvar = self.__dabest_obj._xvar\n",
    "        yvar = self.__dabest_obj._yvar\n",
    "\n",
    "        out = []\n",
    "        reprs = []\n",
    "\n",
    "        for j, current_tuple in enumerate(idx):\n",
    "            if self.__is_paired!=\"sequential\":\n",
    "                cname = current_tuple[0]\n",
    "                control = dat[dat[xvar] == cname][yvar].copy()\n",
    "\n",
    "            for ix, tname in enumerate(current_tuple[1:]):\n",
    "                if self.__is_paired == \"sequential\":\n",
    "                    cname = current_tuple[ix]\n",
    "                    control = dat[dat[xvar] == cname][yvar].copy()\n",
    "                test = dat[dat[xvar] == tname][yvar].copy()\n",
    "\n",
    "                result = TwoGroupsEffectSize(control, test,\n",
    "                                             self.__effect_size,\n",
    "                                             self.__proportional,\n",
    "                                             self.__is_paired,\n",
    "                                             self.__ci,\n",
    "                                             self.__resamples,\n",
    "                                             self.__permutation_count,\n",
    "                                             self.__random_seed)\n",
    "                r_dict = result.to_dict()\n",
    "                r_dict[\"control\"]   = cname\n",
    "                r_dict[\"test\"]      = tname\n",
    "                r_dict[\"control_N\"] = int(len(control))\n",
    "                r_dict[\"test_N\"]    = int(len(test))\n",
    "                out.append(r_dict)\n",
    "                if j == len(idx)-1 and ix == len(current_tuple)-2:\n",
    "                    if self.__delta2 and self.__effect_size == \"mean_diff\":\n",
    "                        resamp_count = False\n",
    "                        def_pval     = False\n",
    "                    elif self.__mini_meta and self.__effect_size == \"mean_diff\":\n",
    "                        resamp_count = False\n",
    "                        def_pval     = False\n",
    "                    else:\n",
    "                        resamp_count = True\n",
    "                        def_pval     = True\n",
    "                else:\n",
    "                    resamp_count = False\n",
    "                    def_pval     = False\n",
    "\n",
    "                text_repr = result.__repr__(show_resample_count=resamp_count,\n",
    "                                            define_pval=def_pval)\n",
    "\n",
    "                to_replace = \"between {} and {} is\".format(cname, tname)\n",
    "                text_repr = text_repr.replace(\"is\", to_replace, 1)\n",
    "\n",
    "                reprs.append(text_repr)\n",
    "\n",
    "        varname = get_varname(self.__dabest_obj)\n",
    "        lastline = \"To get the results of all valid statistical tests, \" +\\\n",
    "        \"use `{}.{}.statistical_tests`\".format(varname, self.__effect_size)\n",
    "        reprs.append(lastline)\n",
    "\n",
    "        reprs.insert(0, print_greeting())\n",
    "\n",
    "        self.__for_print = \"\\n\\n\".join(reprs)\n",
    "\n",
    "        out_             = pd.DataFrame(out)\n",
    "\n",
    "        columns_in_order = ['control', 'test', 'control_N', 'test_N',\n",
    "                            'effect_size', 'is_paired',\n",
    "                            'difference', 'ci',\n",
    "\n",
    "                            'bca_low', 'bca_high', 'bca_interval_idx',\n",
    "                            'pct_low', 'pct_high', 'pct_interval_idx',\n",
    "                            \n",
    "                            'bootstraps', 'resamples', 'random_seed',\n",
    "                            \n",
    "                            'permutations', 'pvalue_permutation', 'permutation_count', 'permutations_var',\n",
    "                            \n",
    "                            'pvalue_welch',\n",
    "                            'statistic_welch',\n",
    "\n",
    "                            'pvalue_students_t',\n",
    "                            'statistic_students_t',\n",
    "\n",
    "                            'pvalue_mann_whitney',\n",
    "                            'statistic_mann_whitney',\n",
    "\n",
    "                            'pvalue_brunner_munzel',\n",
    "                            'statistic_brunner_munzel',\n",
    "\n",
    "                            'pvalue_wilcoxon',\n",
    "                            'statistic_wilcoxon',\n",
    "\n",
    "                            'pvalue_paired_students_t',\n",
    "                            'statistic_paired_students_t',\n",
    "\n",
    "                            'pvalue_kruskal',\n",
    "                            'statistic_kruskal',\n",
    "                            'proportional_difference'\n",
    "                           ]\n",
    "        self.__results   = out_.reindex(columns=columns_in_order)\n",
    "        self.__results.dropna(axis=\"columns\", how=\"all\", inplace=True)\n",
    "\n",
    "        if self.__delta2 is True and self.__effect_size == \"mean_diff\":\n",
    "            self.__delta_delta = DeltaDelta(self,\n",
    "                                            self.__permutation_count,\n",
    "                                            self.__ci)\n",
    "            reprs.append(self.__delta_delta.__repr__(header=False))\n",
    "        elif self.__delta2 is True and self.__effect_size != \"mean_diff\":\n",
    "            self.__delta_delta = \"Delta-delta is not supported for {}.\".format(self.__effect_size)\n",
    "        else:\n",
    "            self.__delta_delta = \"`delta2` is False; delta-delta is therefore not calculated.\"\n",
    "\n",
    "        if self.__mini_meta is True and self.__effect_size == \"mean_diff\":\n",
    "            self.__mini_meta_delta = MiniMetaDelta(self,\n",
    "                                                     self.__permutation_count,\n",
    "                                                     self.__ci)\n",
    "            reprs.append(self.__mini_meta_delta.__repr__(header=False))\n",
    "        elif self.__mini_meta is True and self.__effect_size != \"mean_diff\":\n",
    "            self.__mini_meta_delta = \"Weighted delta is not supported for {}.\".format(self.__effect_size)\n",
    "        else:\n",
    "            self.__mini_meta_delta = \"`mini_meta` is False; weighted delta is therefore not calculated.\"\n",
    "        \n",
    "        varname = get_varname(self.__dabest_obj)\n",
    "        lastline = \"To get the results of all valid statistical tests, \" +\\\n",
    "        \"use `{}.{}.statistical_tests`\".format(varname, self.__effect_size)\n",
    "        reprs.append(lastline)\n",
    "\n",
    "        reprs.insert(0, print_greeting())\n",
    "\n",
    "        self.__for_print = \"\\n\\n\".join(reprs)\n",
    "\n",
    "\n",
    "    def __repr__(self):\n",
    "        try:\n",
    "            return self.__for_print\n",
    "        except AttributeError:\n",
    "            self.__pre_calc()\n",
    "            return self.__for_print\n",
    "            \n",
    "            \n",
    "            \n",
    "    def __calc_lqrt(self):\n",
    "        import lqrt\n",
    "        import pandas as pd\n",
    "        \n",
    "        rnd_seed = self.__random_seed\n",
    "        db_obj = self.__dabest_obj\n",
    "        dat  = db_obj._plot_data\n",
    "        xvar = db_obj._xvar\n",
    "        yvar = db_obj._yvar\n",
    "        delta2 = self.__delta2\n",
    "        \n",
    "\n",
    "        out = []\n",
    "\n",
    "        for j, current_tuple in enumerate(db_obj.idx):\n",
    "            if self.__is_paired != \"sequential\":\n",
    "                cname = current_tuple[0]\n",
    "                control = dat[dat[xvar] == cname][yvar].copy()\n",
    "\n",
    "            for ix, tname in enumerate(current_tuple[1:]):\n",
    "                if self.__is_paired == \"sequential\":\n",
    "                    cname = current_tuple[ix]\n",
    "                    control = dat[dat[xvar] == cname][yvar].copy()\n",
    "                test = dat[dat[xvar] == tname][yvar].copy()\n",
    "                \n",
    "                if self.__is_paired:                    \n",
    "                    # Refactored here in v0.3.0 for performance issues.\n",
    "                    lqrt_result = lqrt.lqrtest_rel(control, test, \n",
    "                                            random_state=rnd_seed)\n",
    "                    \n",
    "                    out.append({\"control\": cname, \"test\": tname, \n",
    "                                \"control_N\": int(len(control)), \n",
    "                                \"test_N\": int(len(test)),\n",
    "                                \"pvalue_paired_lqrt\": lqrt_result.pvalue,\n",
    "                                \"statistic_paired_lqrt\": lqrt_result.statistic\n",
    "                                })\n",
    "\n",
    "                else:\n",
    "                    # Likelihood Q-Ratio test:\n",
    "                    lqrt_equal_var_result = lqrt.lqrtest_ind(control, test, \n",
    "                                                random_state=rnd_seed,\n",
    "                                                equal_var=True)\n",
    "                                                \n",
    "                                                \n",
    "                    lqrt_unequal_var_result = lqrt.lqrtest_ind(control, test, \n",
    "                                                random_state=rnd_seed,\n",
    "                                                equal_var=False)\n",
    "                                                \n",
    "                    out.append({\"control\": cname, \"test\": tname, \n",
    "                                \"control_N\": int(len(control)), \n",
    "                                \"test_N\": int(len(test)),\n",
    "                                \n",
    "                                \"pvalue_lqrt_equal_var\"      : lqrt_equal_var_result.pvalue,\n",
    "                                \"statistic_lqrt_equal_var\"   : lqrt_equal_var_result.statistic,\n",
    "                                \"pvalue_lqrt_unequal_var\"    : lqrt_unequal_var_result.pvalue,\n",
    "                                \"statistic_lqrt_unequal_var\" : lqrt_unequal_var_result.statistic,\n",
    "                                })                     \n",
    "        self.__lqrt_results = pd.DataFrame(out)\n",
    "\n",
    "\n",
    "    def plot(self, color_col=None,\n",
    "\n",
    "            raw_marker_size=6, es_marker_size=9,\n",
    "\n",
    "            swarm_label=None, barchart_label=None, contrast_label=None, delta2_label=None,\n",
    "            swarm_ylim=None, barchart_ylim=None, contrast_ylim=None, delta2_ylim=None,\n",
    "\n",
    "            custom_palette=None, swarm_desat=0.5, halfviolin_desat=1,\n",
    "            halfviolin_alpha=0.8, \n",
    "\n",
    "            face_color = None,\n",
    "            #bar plot\n",
    "            bar_label=None, bar_desat=0.9, bar_width = 0.5,bar_ylim = None,\n",
    "            # error bar of proportion plot\n",
    "            ci=None, err_color=None,\n",
    "\n",
    "            float_contrast=True,\n",
    "            show_pairs=True,\n",
    "            show_delta2=True,\n",
    "            show_mini_meta=True,\n",
    "            group_summaries=None,\n",
    "            group_summaries_offset=0.1,\n",
    "\n",
    "            fig_size=None,\n",
    "            dpi=100,\n",
    "            ax=None,\n",
    "\n",
    "            swarmplot_kwargs=None,\n",
    "            barplot_kwargs=None,\n",
    "            violinplot_kwargs=None,\n",
    "            slopegraph_kwargs=None,\n",
    "            reflines_kwargs=None,\n",
    "            group_summary_kwargs=None,\n",
    "            legend_kwargs=None):\n",
    "\n",
    "        \"\"\"\n",
    "        Creates an estimation plot for the effect size of interest.\n",
    "        \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        color_col : string, default None\n",
    "            Column to be used for colors.\n",
    "        raw_marker_size : float, default 6\n",
    "            The diameter (in points) of the marker dots plotted in the\n",
    "            swarmplot.\n",
    "        es_marker_size : float, default 9\n",
    "            The size (in points) of the effect size points on the difference\n",
    "            axes.\n",
    "        swarm_label, contrast_label, delta2_label : strings, default None\n",
    "            Set labels for the y-axis of the swarmplot and the contrast plot,\n",
    "            respectively. If `swarm_label` is not specified, it defaults to\n",
    "            \"value\", unless a column name was passed to `y`. If\n",
    "            `contrast_label` is not specified, it defaults to the effect size\n",
    "            being plotted. If `delta2_label` is not specifed, it defaults to \n",
    "            \"delta - delta\"\n",
    "        swarm_ylim, contrast_ylim, delta2_ylim : tuples, default None\n",
    "            The desired y-limits of the raw data (swarmplot) axes, the\n",
    "            difference axes and the delta-delta axes respectively, as a tuple. \n",
    "            These will be autoscaled to sensible values if they are not \n",
    "            specified. The delta2 axes and contrast axes should have the same \n",
    "            limits for y. When `show_delta2` is True, if both of the `contrast_ylim`\n",
    "            and `delta2_ylim` are not None, then they must be specified with the \n",
    "            same values; when `show_delta2` is True and only one of them is specified,\n",
    "            then the other will automatically be assigned with the same value.\n",
    "            Specifying `delta2_ylim` does not have any effect when `show_delta2` is\n",
    "            False. \n",
    "        custom_palette : dict, list, or matplotlib color palette, default None\n",
    "            This keyword accepts a dictionary with {'group':'color'} pairings,\n",
    "            a list of RGB colors, or a specified matplotlib palette. This\n",
    "            palette will be used to color the swarmplot. If `color_col` is not\n",
    "            specified, then each group will be colored in sequence according\n",
    "            to the default palette currently used by matplotlib.\n",
    "            Please take a look at the seaborn commands `color_palette`\n",
    "            and `cubehelix_palette` to generate a custom palette. Both\n",
    "            these functions generate a list of RGB colors.\n",
    "            See:\n",
    "            https://seaborn.pydata.org/generated/seaborn.color_palette.html\n",
    "            https://seaborn.pydata.org/generated/seaborn.cubehelix_palette.html\n",
    "            The named colors of matplotlib can be found here:\n",
    "            https://matplotlib.org/examples/color/named_colors.html\n",
    "        swarm_desat : float, default 1\n",
    "            Decreases the saturation of the colors in the swarmplot by the\n",
    "            desired proportion. Uses `seaborn.desaturate()` to acheive this.\n",
    "        halfviolin_desat : float, default 0.5\n",
    "            Decreases the saturation of the colors of the half-violin bootstrap\n",
    "            curves by the desired proportion. Uses `seaborn.desaturate()` to\n",
    "            acheive this.\n",
    "        halfviolin_alpha : float, default 0.8\n",
    "            The alpha (transparency) level of the half-violin bootstrap curves.            \n",
    "        float_contrast : boolean, default True\n",
    "            Whether or not to display the halfviolin bootstrapped difference\n",
    "            distribution alongside the raw data.\n",
    "        show_pairs : boolean, default True\n",
    "            If the data is paired, whether or not to show the raw data as a\n",
    "            swarmplot, or as slopegraph, with a line joining each pair of\n",
    "            observations.\n",
    "        show_delta2, show_mini_meta : boolean, default True\n",
    "            If delta-delta or mini-meta delta is calculated, whether or not to \n",
    "            show the delta-delta plot or mini-meta plot.\n",
    "        group_summaries : ['mean_sd', 'median_quartiles', 'None'], default None.\n",
    "            Plots the summary statistics for each group. If 'mean_sd', then\n",
    "            the mean and standard deviation of each group is plotted as a\n",
    "            notched line beside each group. If 'median_quantiles', then the\n",
    "            median and 25th and 75th percentiles of each group is plotted\n",
    "            instead. If 'None', the summaries are not shown.\n",
    "        group_summaries_offset : float, default 0.1\n",
    "            If group summaries are displayed, they will be offset from the raw\n",
    "            data swarmplot groups by this value. \n",
    "        fig_size : tuple, default None\n",
    "            The desired dimensions of the figure as a (length, width) tuple.\n",
    "        dpi : int, default 100\n",
    "            The dots per inch of the resulting figure.\n",
    "        ax : matplotlib.Axes, default None\n",
    "            Provide an existing Axes for the plots to be created. If no Axes is\n",
    "            specified, a new matplotlib Figure will be created.\n",
    "        swarmplot_kwargs : dict, default None\n",
    "            Pass any keyword arguments accepted by the seaborn `swarmplot`\n",
    "            command here, as a dict. If None, the following keywords are\n",
    "            passed to sns.swarmplot : {'size':`raw_marker_size`}.\n",
    "        violinplot_kwargs : dict, default None\n",
    "            Pass any keyword arguments accepted by the matplotlib `\n",
    "            pyplot.violinplot` command here, as a dict. If None, the following\n",
    "            keywords are passed to violinplot : {'widths':0.5, 'vert':True,\n",
    "            'showextrema':False, 'showmedians':False}.\n",
    "        slopegraph_kwargs : dict, default None\n",
    "            This will change the appearance of the lines used to join each pair\n",
    "            of observations when `show_pairs=True`. Pass any keyword arguments\n",
    "            accepted by matplotlib `plot()` function here, as a dict.\n",
    "            If None, the following keywords are\n",
    "            passed to plot() : {'linewidth':1, 'alpha':0.5}.\n",
    "        reflines_kwargs : dict, default None\n",
    "            This will change the appearance of the zero reference lines. Pass\n",
    "            any keyword arguments accepted by the matplotlib Axes `hlines`\n",
    "            command here, as a dict. If None, the following keywords are\n",
    "            passed to Axes.hlines : {'linestyle':'solid', 'linewidth':0.75,\n",
    "            'zorder':2, 'color' : default y-tick color}.\n",
    "        group_summary_kwargs : dict, default None\n",
    "            Pass any keyword arguments accepted by the matplotlib.lines.Line2D\n",
    "            command here, as a dict. This will change the appearance of the\n",
    "            vertical summary lines for each group, if `group_summaries` is not\n",
    "            'None'. If None, the following keywords are passed to\n",
    "            matplotlib.lines.Line2D : {'lw':2, 'alpha':1, 'zorder':3}.\n",
    "        legend_kwargs : dict, default None\n",
    "            Pass any keyword arguments accepted by the matplotlib Axes\n",
    "            `legend` command here, as a dict. If None, the following keywords\n",
    "            are passed to matplotlib.Axes.legend : {'loc':'upper left',\n",
    "            'frameon':False}.\n",
    "\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        A :class:`matplotlib.figure.Figure` with 2 Axes, if ``ax = None``.\n",
    "        \n",
    "        The first axes (accessible with ``FigName.axes[0]``) contains the rawdata swarmplot; the second axes (accessible with ``FigName.axes[1]``) has the bootstrap distributions and effect sizes (with confidence intervals) plotted on it.\n",
    "        \n",
    "        If ``ax`` is specified, the rawdata swarmplot is accessed at ``ax`` \n",
    "        itself, while the effect size axes is accessed at ``ax.contrast_axes``.\n",
    "        See the last example below.\n",
    "        \n",
    "\n",
    "        Examples\n",
    "        --------\n",
    "        Create a Gardner-Altman estimation plot for the mean difference.\n",
    "\n",
    "        >>> my_data = dabest.load(df, idx=(\"Control 1\", \"Test 1\"))\n",
    "        >>> fig1 = my_data.mean_diff.plot()\n",
    "\n",
    "        Create a Gardner-Altman plot for the Hedges' g effect size.\n",
    "\n",
    "        >>> fig2 = my_data.hedges_g.plot()\n",
    "\n",
    "        Create a Cumming estimation plot for the mean difference.\n",
    "\n",
    "        >>> fig3 = my_data.mean_diff.plot(float_contrast=True)\n",
    "\n",
    "        Create a paired Gardner-Altman plot.\n",
    "\n",
    "        >>> my_data_paired = dabest.load(df, idx=(\"Control 1\", \"Test 1\"),\n",
    "        ...                id_col = \"ID\", paired='baseline')\n",
    "        >>> fig4 = my_data_paired.mean_diff.plot()\n",
    "\n",
    "        Create a multi-group Cumming plot.\n",
    "\n",
    "        >>> my_multi_groups = dabest.load(df, id_col = \"ID\", \n",
    "        ...                             idx=((\"Control 1\", \"Test 1\"),\n",
    "        ...                                 (\"Control 2\", \"Test 2\")))\n",
    "        >>> fig5 = my_multi_groups.mean_diff.plot()\n",
    "\n",
    "        Create a shared control Cumming plot.\n",
    "\n",
    "        >>> my_shared_control = dabest.load(df, id_col = \"ID\",\n",
    "        ...                                 idx=(\"Control 1\", \"Test 1\",\n",
    "        ...                                          \"Test 2\", \"Test 3\"))\n",
    "        >>> fig6 = my_shared_control.mean_diff.plot()\n",
    "        \n",
    "        Create a repeated meausures (against baseline) Slopeplot.\n",
    "\n",
    "        >>> my_rm_baseline = dabest.load(df, id_col = \"ID\", paired = \"baseline\",\n",
    "        ...                                 idx=(\"Control 1\", \"Test 1\",\n",
    "        ...                                          \"Test 2\", \"Test 3\"))\n",
    "        >>> fig7 = my_rm_baseline.mean_diff.plot()\n",
    "\n",
    "        Create a repeated meausures (sequential) Slopeplot.\n",
    "\n",
    "        >>> my_rm_sequential = dabest.load(df, id_col = \"ID\", paired = \"sequential\",\n",
    "        ...                                 idx=(\"Control 1\", \"Test 1\",\n",
    "        ...                                          \"Test 2\", \"Test 3\"))\n",
    "        >>> fig8 = my_rm_sequential.mean_diff.plot()\n",
    "\n",
    "        Creating estimation plots in individual panels of a figure.\n",
    "        \n",
    "        >>> f, axx = plt.subplots(nrows=2, ncols=2, figsize=(15, 15))\n",
    "        >>> my_data.mean_diff.plot(ax=axx.flat[0])\n",
    "        >>> my_data_paired.mean_diff.plot(ax=axx.flat[1])\n",
    "        >>> my_shared_control.mean_diff.plot(ax=axx.flat[2])\n",
    "        >>> my_shared_control.mean_diff.plot(ax=axx.flat[3], float_contrast=False)\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        from .plotter import EffectSizeDataFramePlotter\n",
    "\n",
    "        if hasattr(self, \"results\") is False:\n",
    "            self.__pre_calc()\n",
    "\n",
    "        if self.__delta2:\n",
    "            color_col = self.__x2\n",
    "\n",
    "        # if self.__proportional:\n",
    "        #     raw_marker_size = 0.01\n",
    "            \n",
    "        all_kwargs = locals()\n",
    "        del all_kwargs[\"self\"]\n",
    "\n",
    "        out = EffectSizeDataFramePlotter(self, **all_kwargs)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "    @property\n",
    "    def proportional(self):\n",
    "        \"\"\"\n",
    "        Returns the proportional parameter\n",
    "        class.\n",
    "        \"\"\"\n",
    "        return self.__proportional\n",
    "\n",
    "    @property\n",
    "    def results(self):\n",
    "        \"\"\"Prints all pairwise comparisons nicely.\"\"\"\n",
    "        try:\n",
    "            return self.__results\n",
    "        except AttributeError:\n",
    "            self.__pre_calc()\n",
    "            return self.__results\n",
    "\n",
    "\n",
    "\n",
    "    @property\n",
    "    def statistical_tests(self):\n",
    "        results_df = self.results\n",
    "\n",
    "        # Select only the statistics and p-values.\n",
    "        stats_columns = [c for c in results_df.columns\n",
    "                         if c.startswith(\"statistic\") or c.startswith(\"pvalue\")]\n",
    "\n",
    "        default_cols = ['control', 'test', 'control_N', 'test_N',\n",
    "                        'effect_size', 'is_paired',\n",
    "                        'difference', 'ci', 'bca_low', 'bca_high']\n",
    "\n",
    "        cols_of_interest = default_cols + stats_columns\n",
    "\n",
    "        return results_df[cols_of_interest]\n",
    "\n",
    "\n",
    "    @property\n",
    "    def _for_print(self):\n",
    "        return self.__for_print\n",
    "\n",
    "    @property\n",
    "    def _plot_data(self):\n",
    "        return self.__dabest_obj._plot_data\n",
    "\n",
    "    @property\n",
    "    def idx(self):\n",
    "        return self.__dabest_obj.idx\n",
    "\n",
    "    @property\n",
    "    def xvar(self):\n",
    "        return self.__dabest_obj._xvar\n",
    "\n",
    "    @property\n",
    "    def yvar(self):\n",
    "        return self.__dabest_obj._yvar\n",
    "\n",
    "    @property\n",
    "    def is_paired(self):\n",
    "        return self.__is_paired\n",
    "\n",
    "    @property\n",
    "    def ci(self):\n",
    "        \"\"\"\n",
    "        The width of the confidence interval being produced, in percent.\n",
    "        \"\"\"\n",
    "        return self.__ci\n",
    "\n",
    "    @property\n",
    "    def x1_level(self):\n",
    "        return self.__x1_level\n",
    "\n",
    "\n",
    "    @property\n",
    "    def x2(self):\n",
    "        return self.__x2\n",
    "\n",
    "\n",
    "    @property\n",
    "    def experiment_label(self):\n",
    "        return self.__experiment_label\n",
    "    \n",
    "\n",
    "    @property\n",
    "    def delta2(self):\n",
    "        return self.__delta2\n",
    "    \n",
    "\n",
    "    @property\n",
    "    def resamples(self):\n",
    "        \"\"\"\n",
    "        The number of resamples (with replacement) during bootstrap resampling.\"\n",
    "        \"\"\"\n",
    "        return self.__resamples\n",
    "\n",
    "    @property\n",
    "    def random_seed(self):\n",
    "        \"\"\"\n",
    "        The seed used by `numpy.seed()` for bootstrap resampling.\n",
    "        \"\"\"\n",
    "        return self.__random_seed\n",
    "\n",
    "    @property\n",
    "    def effect_size(self):\n",
    "        \"\"\"The type of effect size being computed.\"\"\"\n",
    "        return self.__effect_size\n",
    "\n",
    "    @property\n",
    "    def dabest_obj(self):\n",
    "        \"\"\"\n",
    "        Returns the `dabest` object that invoked the current EffectSizeDataFrame\n",
    "        class.\n",
    "        \"\"\"\n",
    "        return self.__dabest_obj\n",
    "\n",
    "    @property\n",
    "    def proportional(self):\n",
    "        \"\"\"\n",
    "        Returns the proportional parameter\n",
    "        class.\n",
    "        \"\"\"\n",
    "        return self.__proportional\n",
    "        \n",
    "    @property\n",
    "    def lqrt(self):\n",
    "        \"\"\"Returns all pairwise Lq-Likelihood Ratio Type test results \n",
    "        as a pandas DataFrame.\n",
    "        \n",
    "        For more information on LqRT tests, see https://arxiv.org/abs/1911.11922\n",
    "        \"\"\"\n",
    "        try:\n",
    "            return self.__lqrt_results\n",
    "        except AttributeError:\n",
    "            self.__calc_lqrt()\n",
    "            return self.__lqrt_results\n",
    "        \n",
    "    \n",
    "    @property\n",
    "    def mini_meta(self):\n",
    "        \"\"\"\n",
    "        Returns the mini_meta boolean parameter.\n",
    "        \"\"\"\n",
    "        return self.__mini_meta\n",
    "\n",
    "    \n",
    "    @property\n",
    "    def mini_meta_delta(self):\n",
    "        \"\"\"\n",
    "        Returns the mini_meta results.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            return self.__mini_meta_delta\n",
    "        except AttributeError:\n",
    "            self.__pre_calc()\n",
    "            return self.__mini_meta_delta\n",
    "\n",
    "    \n",
    "    @property\n",
    "    def delta_delta(self):\n",
    "        \"\"\"\n",
    "        Returns the mini_meta results.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            return self.__delta_delta\n",
    "        except AttributeError:\n",
    "            self.__pre_calc()\n",
    "            return self.__delta_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def print_greeting():\n",
    "    # from .__init__ import __version__\n",
    "    import datetime as dt\n",
    "    import numpy as np\n",
    "\n",
    "    line1 = \"DABEST v{}\".format(__version__)\n",
    "    header = \"\".join(np.repeat(\"=\", len(line1)))\n",
    "    spacer = \"\".join(np.repeat(\" \", len(line1)))\n",
    "\n",
    "    now = dt.datetime.now()\n",
    "    if 0 < now.hour < 12:\n",
    "        greeting = \"Good morning!\"\n",
    "    elif 12 < now.hour < 18:\n",
    "        greeting = \"Good afternoon!\"\n",
    "    else:\n",
    "        greeting = \"Good evening!\"\n",
    "\n",
    "    current_time = \"The current time is {}.\".format(now.ctime())\n",
    "\n",
    "    return \"\\n\".join([line1, header, spacer, greeting, current_time])\n",
    "\n",
    "\n",
    "def get_varname(obj):\n",
    "    matching_vars = [k for k,v in globals().items() if v is obj]\n",
    "    if len(matching_vars) > 0:\n",
    "        return matching_vars[0]\n",
    "    else:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def load(data, idx=None, x=None, y=None, paired=None, id_col=None,\n",
    "        ci=95, resamples=5000, random_seed=12345, proportional=False, \n",
    "        delta2 = False, experiment = None, experiment_label = None,\n",
    "        x1_level = None, mini_meta=False):\n",
    "    '''\n",
    "    Loads data in preparation for estimation statistics.\n",
    "\n",
    "    This is designed to work with pandas DataFrames.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pandas DataFrame\n",
    "    idx : tuple\n",
    "        List of column names (if 'x' is not supplied) or of category names\n",
    "        (if 'x' is supplied). This can be expressed as a tuple of tuples,\n",
    "        with each individual tuple producing its own contrast plot\n",
    "    x : string or list, default None\n",
    "        Column name(s) of the independent variable. This can be expressed as\n",
    "        a list of 2 elements if and only if 'delta2' is True; otherwise it \n",
    "        can only be a string.\n",
    "    y : string, default None\n",
    "        Column names for data to be plotted on the x-axis and y-axis.\n",
    "    paired : string, default None\n",
    "        The type of the experiment under which the data are obtained\n",
    "    id_col : default None.\n",
    "        Required if `paired` is True.\n",
    "    ci : integer, default 95\n",
    "        The confidence interval width. The default of 95 produces 95%\n",
    "        confidence intervals.\n",
    "    resamples : integer, default 5000.\n",
    "        The number of resamples taken to generate the bootstraps which are used\n",
    "        to generate the confidence intervals.\n",
    "    random_seed : int, default 12345\n",
    "        This integer is used to seed the random number generator during\n",
    "        bootstrap resampling, ensuring that the confidence intervals\n",
    "        reported are replicable.\n",
    "    proportional : boolean, default False. \n",
    "        TO INCLUDE MORE DESCRIPTION ABOUT DATA FORMAT\n",
    "    delta2 : boolean, default False\n",
    "        Indicator of delta-delta experiment\n",
    "    experiment : String, default None\n",
    "        The name of the column of the dataframe which contains the label of \n",
    "        experiments\n",
    "    experiment_lab : list, default None\n",
    "        A list of String to specify the order of subplots for delta-delta plots.\n",
    "        This can be expressed as a list of 2 elements if and only if 'delta2' \n",
    "        is True; otherwise it can only be a string. \n",
    "    x1_level : list, default None\n",
    "        A list of String to specify the order of subplots for delta-delta plots.\n",
    "        This can be expressed as a list of 2 elements if and only if 'delta2' \n",
    "        is True; otherwise it can only be a string. \n",
    "    mini_meta : boolean, default False\n",
    "        Indicator of weighted delta calculation.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A `Dabest` object.\n",
    "\n",
    "    Example\n",
    "    --------\n",
    "    Load libraries.\n",
    "\n",
    "    >>> import numpy as np\n",
    "    >>> import pandas as pd\n",
    "    >>> import dabest\n",
    "\n",
    "    Create dummy data for demonstration.\n",
    "\n",
    "    >>> np.random.seed(88888)\n",
    "    >>> N = 10\n",
    "    >>> c1 = sp.stats.norm.rvs(loc=100, scale=5, size=N)\n",
    "    >>> t1 = sp.stats.norm.rvs(loc=115, scale=5, size=N)\n",
    "    >>> df = pd.DataFrame({'Control 1' : c1, 'Test 1': t1})\n",
    "\n",
    "    Load the data.\n",
    "\n",
    "    >>> my_data = dabest_nbdev.load(df, idx=(\"Control 1\", \"Test 1\"))\n",
    "\n",
    "    '''\n",
    "\n",
    "    return Dabest(data, idx, x, y, paired, id_col, ci, resamples, random_seed, proportional, delta2, experiment, experiment_label, x1_level, mini_meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dummy data for demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# np.random.seed(88888)\n",
    "# N = 10\n",
    "# c1 = norm.rvs(loc=100, scale=5, size=N)\n",
    "# t1 = norm.rvs(loc=115, scale=5, size=N)\n",
    "# df = pd.DataFrame({'Control 1' : c1, 'Test 1': t1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DABEST v0.3.1\n",
       "=============\n",
       "             \n",
       "Good morning!\n",
       "The current time is Sun Jan  8 01:19:17 2023.\n",
       "\n",
       "Effect size(s) with 95% confidence intervals will be computed for:\n",
       "1. Test 1 minus Control 1\n",
       "\n",
       "5000 resamples will be used to generate the effect size bootstraps."
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "# two_groups_unpaired = load(df, idx=(\"Control 1\", \"Test 1\"), resamples=5000)\n",
    "# two_groups_unpaired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
